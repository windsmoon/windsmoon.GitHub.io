<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[C# 实现撤销与重做]]></title>
    <url>%2F2018%2F12%2F06%2FC%23%20%E5%AE%9E%E7%8E%B0%E6%92%A4%E9%94%80%E4%B8%8E%E9%87%8D%E5%81%9A%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！如果在第三方阅读发现公式等格式有问题，请到原文地址阅读。 概要编辑器开发以及一些特定类型的游戏开发过程中，经常会遇到撤销（Undo）和重做（Redo）的功能，即常见的 Crtl + Z 相关的功能。此功能看起来简单，但如果不进行一定的设计，会导致代码爆炸（每一个操作都要硬编码撤销和重做代码）。 我在给项目做地图编辑器的时候，自然也需要实现撤销和重做的功能，在这篇文章中我会分享一下我的做法。先说一下，我的想法是基于《游戏编程模式》一书中【命令模式】这一章中所讲的内容，但是书中对撤销与重做的例子过于简单，只有单个命令的撤销和重做，在这篇文章中，我会完整实现一个撤销与重做的框架并用 Unity 实现一个编辑器例子。 为了方便，本文中除了一个自己编写的双端队列数据结构外，其余所有代码都放在 Windsmoon 这个 namespace 下。 命令模式此功能需要用到一种叫做命令模式的设计模式，就是把操作封装成一个命令，通俗易懂地说就是设计一个 Command 类，其中包含 Excute 和 Undo 两个方法。Excute 用于执行此命令，Undo 用于撤销此操作，但 Excute 还有一个功能，就是还可以 Redo 即重做之前 Undo 方法撤销的操作。代码很简单： 123456789101112131415namespace Windsmoon&#123; public abstract class Command &#123; #region methods public abstract void Excute(); public abstract void Undo(); public override string ToString() &#123; return &quot;This is a command without info&quot;; &#125; #endregion &#125;&#125; 当然这个 Command 是个基类，具体的命令要继承自它，并重写它的方法。当要执行某个操作的时候，需要编写特定的 XXXCommand 并继承自 Command，然后执行，撤销和重做就是调用其中的 Undo 和 Excute（前面说过 Excute 兼具 Redo 的功能）。 命令池数据结构要撤销或者重做某个 Command，自然需要一个数据结构去存储这些 Command，否则就无法找到需要的 Command。这里我姑且称之为命令池，之前我叫做 UndoPool，但是感觉容易引起混淆，因为它是把 Undo 和 Redo 合在一起的。设计这个数据结构之前，可以从需求入手。 撤销需求假设 ABC 分别是三个操作，当以 ABC 的顺序执行之后，想要全被撤销它们，显然是要以 CBA 的顺序进行撤销，这是一个典型的【后进先出】数据结构，很简单就不做过多解释了，可以以一个栈去保存这些操作过的命令，然后从这个栈中去取栈顶的命令进行撤销。 重做需求重做一定是在撤销之后的，因为没有撤销的操作，就没有重做的对象。所以当以 ABC 的顺序执行操作，再以 CBA 的方式进行撤销之后，此时又想要重做这三个操作（当然顺序只能是 ABC，这是正常逻辑），稍加思考就可以得知撤销的 CBA 和重做的 ABC 又是一个后进先出，所以可以再用一个栈去保存进行过撤销的操作，然后就可以从这个栈中取出栈顶的命令进行重做。 撤销和重做的联系取出待重做栈中的命令进行重做后，这个命令就被丢弃了吗，并不是，因为这个命令还可以再次被撤销。所以，这两个栈之间可以互相存取。即执行操作时，入【待撤销栈】，撤销时，从【待撤销栈】取出，入【待重做栈】，重做时，从【待重做栈】取出，入【待撤销栈】。顺着这个思路用 ABC 三个操作进行一下思考，就可以知道不一定要 ABC 全部撤销才可以开始重做，可以从这中间任何一个地方开始操作。有一点稍微特殊的是，当有一部分但不是全部操作从【待撤销栈】进入到【待重做栈】时，此时再进行正常的操作，就会有新的命令进入【待撤销栈】，这时【待重做栈】要如何处理呢？我问了一圈其他编辑工具的使用者，发现这时候就不允许再进行重写操作了，即进入了一个新的周期，所以这种情况下直接把【待重做栈】清空即可。 双端队列看起来只需要两个栈就可以实现了，但实际上，我并没有用两个栈，因为用两个栈去操作会遇到一个问题：当你设定了一个最大可撤销数量时（一般都会有这个设定，毕竟内存不是无限大的），试想一下【待撤销栈】已经满了，当下一个命令准备入栈时，显然不能把这个命令丢弃掉而留下之前的操作，这会导致撤销时跳过了一个命令，所以我们需要把这个命令入栈，还要把栈底的命令踢出去。这不符合栈的数据结构设计，不过我们可以用【队列】来代替，但是用【队列】会造成无法取出正确的命令进行撤销（因为队列是一头进另一头出），所以最终的数据结构是【双端队列】，这样就可以在两端进行入队和出队操作了。 双端队列不在本文的讲解范围内，有问题的同学自行查阅即可，值得注意的是，C# 并没有内置的双端队列实现（至少我用的 Unity 版本没有），所以我仿照 .Net 的风格自己写了一个双端队列的实现，除了基础数据结构功能外也实现了迭代器等操作，基本和 C# 内置的 Queue 差不太多，代码直接在 Github 上看就可以了 C# 双端队列，基本就是 AddHead/Tail，RemoveHead/Tail 这样的命名。 设置的命令数量上限是针对待撤销的命令而言的，【待重做栈】是不需要考虑这个的。当【待撤销队列】（代替之前的【待撤销栈】）已经满了的时候，【待重做栈】一定是空的，否则就说明有操作被撤销了，即【待撤销队列】中有了空位（如前所说，每次【待撤销队列】有新元素加入时，【待重做栈】都会被清空）。所以【待重做栈】的数据结构不需要变动。 代码实现以下是命令池的关键代码实现，完整代码可以参考 Github 上的源码 CommandPool ： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687using System;using System.Collections.Generic;namespace Windsmoon&#123; public class CommandPool &#123; #region fields private Stack&lt;Command&gt; undidStack; private int maxCommandCount; private Deque&lt;Command&gt; didDeque; #endregion #region properties public int TotalCommandCount &#123; get &#123; return didDeque.Count; &#125; &#125; public int UndidCommandCount &#123; get &#123; return undidStack.Count; &#125; &#125; public int DidCommandCount &#123; get &#123; return didDeque.Count; &#125; &#125; #endregion #region constructors public CommandPool(int maxCommandCount) &#123; didDeque = new Deque&lt;Command&gt;(maxCommandCount); undidStack = new Stack&lt;Command&gt;(); this.maxCommandCount = maxCommandCount; &#125; #endregion #region methods public void Register(Command command) &#123; undidStack.Clear(); if (didDeque.Count == maxCommandCount) &#123; didDeque.RemoveHead(); &#125; didDeque.AddTail(command); &#125; public void Undo() &#123; if (didDeque.Count == 0) &#123; return; &#125; Command command = didDeque.RemoveTail(); command.Undo(); undidStack.Push(command); &#125; public void Redo() &#123; if (undidStack.Count == 0) &#123; return; &#125; Command command = undidStack.Pop(); command.Excute(); didDeque.AddTail(command); &#125; #endregion &#125;&#125; 我只贴了关键的字段和方法，逻辑很简单， 在适当的地方 new 一个 CommandPool 对象，当要执行一个操作的时候，new 一个对应的 Command 子类，然后调用 CommandPool.Register 方法把它注册到【待撤销队列 】中。要执行撤销的时候就执行 CommandPool.Undo 方法，要执行重做的时候就执行 CommandPool.Redo 方法，其内部的操作就和之前描述的一样。 至此，一个命令池就完成了，后面我会用这些框架代码和 Unity 游戏引擎去实现一个编辑器撤销重做的例子。没有接触过 Unity 的同学也不必担心，我不会过多讲例子中的细节，只会给出其中方法的大概含义，不过需要安装 Unity 才能观察效果。如果你想在别的地方使用这套代码，直接把上面提到的文件拷贝走就可以使用了。 注意下面的例子是拿 Unity 做的一个小编辑器扩展，不了解 Unity 的同学或者前面代码已经明白了的同学可以直接跳过例子章节到后面的经验总结部分。 下面的例子是拿 Unity 做的一个小编辑器扩展，不了解 Unity 的同学或者前面代码已经明白了的同学可以直接跳过例子章节到后面的经验总结部分。 下面的例子是拿 Unity 做的一个小编辑器扩展，不了解 Unity 的同学或者前面代码已经明白了的同学可以直接跳过例子章节到后面的经验总结部分。 例子Unity 的例子工程地址是 Unity 例子，代码中有两个文件夹（在 Assets/Srcipts 文件夹下），Core 就是功能的核心代码，直接拷贝这个文件夹下的代码就可以在任意 C# 项目中使用，UnityCode 文件夹是存放 Unity 例子相关的代码的。 例子的功能是创建一个 10 x 10 的网格，鼠标点击网格会在其上生成一个立方体（一个格子只有一个），按住 Ctrl 再点击会把立方体删除掉。 在 UnityCode 中，有以下几个文件，每个文件对应一个类： UndoRedoManager 用来引用 CommandPool 的实例，并且创建了三个按钮，分别是生成场景，Undo，Redo，在 Unity 上方菜单栏找到【UndoRedo】按钮，点开即可看到。 Raycaster 这个类用来处理点击事件，当鼠标点中时，会根据是否按住 Ctrl 来做不同的操作。 SceneMonobehaviour 用来和 Raycaster 一起工作的类，在这个例子里实际是个空类，这是 Unity 的编程风格，不必纠结。 CreateCubeCommand 继承自 Command 类，把生成立方体的操作封装成类，以便用于 Undo 和 Redo。 DestoryCubeCommand 继承自 Command 类，把销毁立方体的操作封装成类，以便用于 Undo 和 Redo。 下面我会大致讲讲这个例子，不必细看，实际上把例子之前的那些代码拷贝过去就可以用了。 首先点击按钮生成网格后，在选中生成的 Scene 物体（不用纠结为什么），单纯点击鼠标会调用到 Raycaster.CreateCube 方法， 代码如下： 12345678private void CreateCube(Event currentEvent)&#123; ... // 判断是否已有立方体等操作 CreateCubeCommand createCubeCommand = new CreateCubeCommand(CreateCubeImpl, DestroyCubeImpl, raycastHit); // 1 UndoRedoManager.CommandPool.Register(createCubeCommand); // 2 createCubeCommand.Excute(); // 3&#125; 我只把关键的三行放在上面，第 1 行，new 一个 CreateCubeCommand 对象，构造函数代码如下： 1234567891011121314#region fieldsprivate RaycastHit raycastHit;private Action&lt;RaycastHit&gt; excuteAction;private Action&lt;RaycastHit&gt; undoAction;#endregion#region constructorspublic CreateCubeCommand(Action&lt;RaycastHit&gt; excuteAction, Action&lt;RaycastHit&gt; undoAction, RaycastHit raycastHit)&#123; this.excuteAction = excuteAction; this.undoAction = undoAction; this.raycastHit = raycastHit;&#125;#endregion 三个参数分别是执行函数，撤销函数，以及一个 RaycastHit 对象（在这里是用来存储点击位置的信息的，不用纠结）。继承自 Command 类要重写 Excute 和 Undo 方法，在这个类中是非常简单的实现： 123456789public override void Excute()&#123; excuteAction(raycastHit);&#125;public override void Undo()&#123; undoAction(raycastHit);&#125; 代码如上所示，就是直接调用传入构造函数的方法。 第 2 行，把 Command 的实例注册到 CommandPool 中，第 3 行，执行此次操作。至此，一个操作就做完并且注册到命令池中了。之后只要调用 CommandPool.Undo 和 CommandPool.Redo 方法就可以进行撤销和重做了。 执行操作的时机也可以手动调用操作的函数，不用 Command.Excute 方法，并且具体的执行和撤销代码也可以直接放在 Command 中的 Excute 和 Undo 方法中，不必像例子中那样传入两个函数。 当按住 Ctrl 再点击鼠标，会执行 DestroyCube 方法， 1234567 private void DestroyCube(Event currentEvent) &#123;... /// 各种判断 DestoryCubeCommand destoryCubeCommand = new DestoryCubeCommand(DestroyCubeImpl, CreateCubeImpl, raycastHit); UndoRedoManager.CommandPool.Register(destoryCubeCommand); destoryCubeCommand.Excute(); &#125; 这个方法是与前面 Create 正好相反的（注意构造函数的参数），核心代码就这么多，有 Unity 的同学可以试一试。 一些经验总结我自己在使用的过程中，遇到了一些小坑，总结了一些经验： 当你有相反的操作的时候，例如上面例子中的创建与删除时，可以只用一个 Command 子类，只需要传入一个创建还是销毁的标记即可，但是我不建议这么做，因为很容易乱，尤其是操作复杂以及有很多种操作的时候。可以自己再重新划分继承树的结构，总之建议每个操作对应一个单独的类。 是传入数据参数，直接在 Excute 和 Undo 里写具体的操作代码，还是在外部写好作文函数传入，这个我个人觉得都可以，但我比较喜欢作为函数传入，这样在操作需要涉及很多变量的时候会方便一些。 结尾这篇文章中的代码与我在项目中使用的略有不同（没有本质的区别），但这里的代码，测试只是靠上面开发的 Unity 的例子进行测试，如果发现了 bug，还请告诉我，谢谢～（应该没什么问题，毕竟项目里都用了好久了） 感谢阅读～]]></content>
      <categories>
        <category>编辑器</category>
      </categories>
      <tags>
        <tag>编辑器 游戏开发 C# 撤销</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C# 撤销与重做]]></title>
    <url>%2F2018%2F05%2F26%2FC%23%20%E6%92%A4%E9%94%80%E4%B8%8E%E9%87%8D%E5%81%9A%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！如果在第三方阅读发现公式等格式有问题，请到原文地址阅读。 原文地址 概要最近两三周在写 Unity 的编辑器扩展，主要是给项目开发一个地图编辑器，期间遇到了一些坑，所以有了开个系列记录一下的想法。这是第一篇，我希望不要再有第二篇了。 我目前使用的版本是 Unity 2017.1.3.f1。 问题与解决方案数据序列化写编辑器扩展，如果需要保存数据到文件，序列化数据是必不可少的。我目前用过两个方案，一个是利用 Unity 自身的序列化系统配合 ScriptableObject，一个是利用 C# 的序列化 API ，这两种方式各有优劣。 C# 序列化C# 序列化方便快捷，但是在 Unity 中不一定好用。如果需要用 C# 的序列化，class 或者 struct 必须加上 Serializable 这个 Attribute，然而可能大部分你想序列化的 C# 内置 class 或者 struct，都没加这个 Attribute，例如 VectorX 系列，还有 ScriptableObject。之前需要用 C# 序列化的时候，Vector2 和 Vector3 等我都自己实现了一个可序列化版本。 C# 序列化在 Unity 中还有一个问题，就是不如内置序列化系统方便，因为 Unity 的序列化几乎每时每刻都在进行，虽然有相应接口，但你必须确保在必须要序列化的时机进行序列化，以免数据被清空。 Unity 内置序列化Unity 内置序列化系统以及一些配套组件（例如 ScriptableObject 等）在 Unity 中能保证序列化和反序列化的数据正确性，并且几乎不需要关心序列化的时机，只需要指明哪些数据需要序列化即可。一般来说，在会被 Unity 进行序列化的内置类中，public 字段和被 SerializeField 这个 Attribute 修饰的字段会被序列化，例如 MonoBehaviour 中的字段，ScriptableObject 也是，其他自定义类我没验证过，但是 private 的我都加了 SerializeField 这个标签没有问题，public 的也可以正确序列化。 但是不是所有类型都能序列化的！在常用的需要序列化的类中，Dictionary 和二维数组以及其他有嵌套关系的容器（目前看来是这样，不能保证所有这种容器一定不能被序列化）不能被序列化。好在都有解决办法。 序列化 Dictionary虽然 Dictionary 不能被 Unity 序列化，但是 List 是可以的，我们可以把 Dictionary 的 keys 和 values 保存在两个 List 里，这样就可以序列化和反序列化字典了。注意我不是说要用两个 List 完全代替 Dictionary 这个数据结构，这样就失去了 Dictionary 的数据结构特性了，我们只需要在 Unity 进行序列化和反序列化的时候把 Dictionary 挪到两个 List 里和从 两个 List 里复原 Dictionary 就行了。Unity 进行序列化和反序列化的时机是可以知道的，关键在于一个 interface。 123456789101112131415161718using UnityEngine.Scripting;namespace UnityEngine&#123; [RequiredByNativeCode] public interface ISerializationCallbackReceiver &#123; /// &lt;summary&gt; /// &lt;para&gt;Implement this method to receive a callback before Unity serializes your object.&lt;/para&gt; /// &lt;/summary&gt; void OnBeforeSerialize (); /// &lt;summary&gt; /// &lt;para&gt;Implement this method to receive a callback after Unity deserializes your object.&lt;/para&gt; /// &lt;/summary&gt; void OnAfterDeserialize (); &#125;&#125; 这个 interface 有两个方法，OnBeforeSerialize 在将要序列化的时候执行，OnAfterDeserialize 在反序列化完成后执行。 所以我们只需要在 OnBeforeSerialize 中把 keys 和 values 保存到两个 List 里，在 OnAfterDeserialize 中根据两个 List 中的数据重建一个 Dictionary 就行了。 123456789101112131415161718192021public void OnBeforeSerialize()&#123; keyList.Clear(); valueList.Clear(); foreach (var pair in dataDict) &#123; keyList.Add(pair.Key); valueList.Add(pair.Value); &#125;&#125;public void OnAfterDeserialize()&#123; dataDict.Clear(); for (int i = 0; i &lt; keyList.Count; ++i) &#123; dataDict[keyList[i]] = valueList[i]; &#125;&#125; 要注意的是这个 interface 目前不支持 struct 。 嵌套容器如果是类似这样的数据， 1Dictionary&lt;int, X[]&gt; 则里面的 X[] 是不能被序列化的，但是如果你将 X[] 写在一个类里。 12345public class XWrapper&#123; [SerializeField] private X[] Xs;&#125; 外部容器保存这个 XWrapper ，就可以正确序列化数组中的数据了。所以如果你在使用嵌套容器的时候出现问题，可以考虑这种方法。 内存数据清空写编辑器代码的时候，会有一些情况导致内存中的数据被清空，我判断内存数据被清空重置的方式是观察静态构造函数在控制台的输出。目前我遇到的情况有： 编译代码：代码修改后 Unity 会进行重新编译，并把内存清空重置，重新加载代码。例如一个没有被序列化的变量被赋值以后，再修改代码，编译完成后这个变量的值就为 null 或者默认的值类型数据了。我在某个类的静态构造函数内输出一段字符串到控制台，当重新编译代码的时候，访问这个类，控制台会进行输出，但之后再次访问就不会，这说明代码没有被重新加载，但是当更改代码并进行编译后，第一次访问这个类依然会有输出，这足以说明问题。这里有一个需要注意的点是，修改代码后，并不会立即进行编译。一般来说，会等一会儿才开始编译，且代码编译的时候会有卡顿，并且编译完成后控制台里也会输出各种警告（如果有的话），这时候就说明编译完成了。也就是说你必须等待一会儿才行，如果你改完代码后立即回到编辑器里执行你写的代码，这时候实际上还是之前的代码。有一个小技巧是可以改完代码点运行，运行前会进行代码编译，运行开始就说明是新的代码了，这样做的好处是你可以确保代码是新的代码，但必须注意运行也会把没序列化的数据清除。 运行：点击运行按钮的时候，会进行数据的重置，我在某个 MonoBehaviour 的 Awake 方法里访问上面提到的类，每次都会有输出。但是运行还需要注意的是，Unity 点击运行会把没有进行序列化的数据丢掉，这时退出运行，之前在编辑器状态下设置好的数据就没了。序列化的数据，这里是指 MonoBehaviour 中访问修饰符为 public 的变量和拥有 SerializeField 这个 Attribute 的变量。 退出运行不会进行内存重置，但很重要 ，因为退出也相当于加载了场景，会执行 Awake 等相关函数，如果你有一些初始化函数在这时候执行，你需要注意它是否会影响到你。 ScriptableObject这个类看似很简单，但是第一次使用却花费了我很长时间来与其搏斗。这个类主要用来进行数据交互，它不需要挂在 GameObject 上，可以作为单独的数据存储来使用。在写编辑器扩展的时候使用它，有不少地方需要注意。 ScriptableObject 与 AssetScriptableObject 可以保存为 Asset，而且实际使用时发现，如果你不保存成 Asset，相关的引用就会在某些时候变为空。例如使用 ScriptableObject.CreateInstance 创建 一个 ScriptableObject 后，把它保存在容器里，然后函数结束。当你下次再用，就会发现这个引用变为 null 了。如果 ScriptableObject.CreateInstance 之后把这个 ScriptableObject 保存为 Asset，则没有问题。 删除 ScriptablObject Asset如果使用诸如 AssetDatabase.LoadAsset&lt;&gt; 之类的函数把 ScriptableObject Asset 加载进来，然后保存在一个 MonoBehaviour 的变量里，当你删除这个 Asset 时，这个变量也为空了。也就是说，如果是直接加载这个 ScriptableObject Asset，当 Asset 被删除，加载进来的对象也没了（我原本以为挂在物体上的数据还会保留 ）。 这个不注意可能会有一些致命的问题，例如你有个 ScriptableObject Asset，里面可能还有很多子 ScriptableObject Asset，策划想要用你的编辑器继续做上次没完成的工作，于是把上次保存好的 ScriptableObject Asset 加载进来进行操作，操作完毕后进行保存，可能会直接选择上次的路径，代码里可能会使用 AssetDatabase.CreateAsset 等方法，这实际上会覆盖原先的资源，也就是说之前的资源被删掉了。这时问题就来了，资源被删除后，Scene 中的数据也没了，这时保存代码执行，自然什么也保存不到。 解决方案是加载后使用 Instantiate&lt;&gt; 去复制出一个 ScriptableObject，之后都操作这个复制出来的，或者干脆用 ScriptableObject.CreateInstance 创建一个新的（要注意上面提到的问题，最好创建完后立即使用或者挂在物体上）。 枚举保存数据的时候，尽可能不要用枚举作为 key ，因为一旦枚举因为一些原因，数值有变化，数据可能取不出来。可以考虑转成字符串。参考了下 C# 的源码，枚举在进行 GetHashCode 的时候，貌似是用它的数值进行操作的。 结语这次暂时写这么多，再次希望不要有第二篇。以上如果有朋友知道更准确的原因，可以留言。感谢大家阅读。]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity 编辑器扩展 游戏开发 Unity序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity 编辑器扩展和序列化踩坑记（一）]]></title>
    <url>%2F2018%2F05%2F26%2FUnity%20%E7%BC%96%E8%BE%91%E5%99%A8%E6%89%A9%E5%B1%95%E8%B8%A9%E5%9D%91%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！如果在第三方阅读发现公式等格式有问题，请到原文地址阅读。 原文地址 概要最近两三周在写 Unity 的编辑器扩展，主要是给项目开发一个地图编辑器，期间遇到了一些坑，所以有了开个系列记录一下的想法。这是第一篇，我希望不要再有第二篇了。 我目前使用的版本是 Unity 2017.1.3.f1。 问题与解决方案数据序列化写编辑器扩展，如果需要保存数据到文件，序列化数据是必不可少的。我目前用过两个方案，一个是利用 Unity 自身的序列化系统配合 ScriptableObject，一个是利用 C# 的序列化 API ，这两种方式各有优劣。 C# 序列化C# 序列化方便快捷，但是在 Unity 中不一定好用。如果需要用 C# 的序列化，class 或者 struct 必须加上 Serializable 这个 Attribute，然而可能大部分你想序列化的 C# 内置 class 或者 struct，都没加这个 Attribute，例如 VectorX 系列，还有 ScriptableObject。之前需要用 C# 序列化的时候，Vector2 和 Vector3 等我都自己实现了一个可序列化版本。 C# 序列化在 Unity 中还有一个问题，就是不如内置序列化系统方便，因为 Unity 的序列化几乎每时每刻都在进行，虽然有相应接口，但你必须确保在必须要序列化的时机进行序列化，以免数据被清空。 Unity 内置序列化Unity 内置序列化系统以及一些配套组件（例如 ScriptableObject 等）在 Unity 中能保证序列化和反序列化的数据正确性，并且几乎不需要关心序列化的时机，只需要指明哪些数据需要序列化即可。一般来说，在会被 Unity 进行序列化的内置类中，public 字段和被 SerializeField 这个 Attribute 修饰的字段会被序列化，例如 MonoBehaviour 中的字段，ScriptableObject 也是，其他自定义类我没验证过，但是 private 的我都加了 SerializeField 这个标签没有问题，public 的也可以正确序列化。 但是不是所有类型都能序列化的！在常用的需要序列化的类中，Dictionary 和二维数组以及其他有嵌套关系的容器（目前看来是这样，不能保证所有这种容器一定不能被序列化）不能被序列化。好在都有解决办法。 序列化 Dictionary虽然 Dictionary 不能被 Unity 序列化，但是 List 是可以的，我们可以把 Dictionary 的 keys 和 values 保存在两个 List 里，这样就可以序列化和反序列化字典了。注意我不是说要用两个 List 完全代替 Dictionary 这个数据结构，这样就失去了 Dictionary 的数据结构特性了，我们只需要在 Unity 进行序列化和反序列化的时候把 Dictionary 挪到两个 List 里和从 两个 List 里复原 Dictionary 就行了。Unity 进行序列化和反序列化的时机是可以知道的，关键在于一个 interface。 123456789101112131415161718using UnityEngine.Scripting;namespace UnityEngine&#123; [RequiredByNativeCode] public interface ISerializationCallbackReceiver &#123; /// &lt;summary&gt; /// &lt;para&gt;Implement this method to receive a callback before Unity serializes your object.&lt;/para&gt; /// &lt;/summary&gt; void OnBeforeSerialize (); /// &lt;summary&gt; /// &lt;para&gt;Implement this method to receive a callback after Unity deserializes your object.&lt;/para&gt; /// &lt;/summary&gt; void OnAfterDeserialize (); &#125;&#125; 这个 interface 有两个方法，OnBeforeSerialize 在将要序列化的时候执行，OnAfterDeserialize 在反序列化完成后执行。 所以我们只需要在 OnBeforeSerialize 中把 keys 和 values 保存到两个 List 里，在 OnAfterDeserialize 中根据两个 List 中的数据重建一个 Dictionary 就行了。 123456789101112131415161718192021public void OnBeforeSerialize()&#123; keyList.Clear(); valueList.Clear(); foreach (var pair in dataDict) &#123; keyList.Add(pair.Key); valueList.Add(pair.Value); &#125;&#125;public void OnAfterDeserialize()&#123; dataDict.Clear(); for (int i = 0; i &lt; keyList.Count; ++i) &#123; dataDict[keyList[i]] = valueList[i]; &#125;&#125; 要注意的是这个 interface 目前不支持 struct 。 嵌套容器如果是类似这样的数据， 1Dictionary&lt;int, X[]&gt; 则里面的 X[] 是不能被序列化的，但是如果你将 X[] 写在一个类里。 12345public class XWrapper&#123; [SerializeField] private X[] Xs;&#125; 外部容器保存这个 XWrapper ，就可以正确序列化数组中的数据了。所以如果你在使用嵌套容器的时候出现问题，可以考虑这种方法。 内存数据清空写编辑器代码的时候，会有一些情况导致内存中的数据被清空，我判断内存数据被清空重置的方式是观察静态构造函数在控制台的输出。目前我遇到的情况有： 编译代码：代码修改后 Unity 会进行重新编译，并把内存清空重置，重新加载代码。例如一个没有被序列化的变量被赋值以后，再修改代码，编译完成后这个变量的值就为 null 或者默认的值类型数据了。我在某个类的静态构造函数内输出一段字符串到控制台，当重新编译代码的时候，访问这个类，控制台会进行输出，但之后再次访问就不会，这说明代码没有被重新加载，但是当更改代码并进行编译后，第一次访问这个类依然会有输出，这足以说明问题。这里有一个需要注意的点是，修改代码后，并不会立即进行编译。一般来说，会等一会儿才开始编译，且代码编译的时候会有卡顿，并且编译完成后控制台里也会输出各种警告（如果有的话），这时候就说明编译完成了。也就是说你必须等待一会儿才行，如果你改完代码后立即回到编辑器里执行你写的代码，这时候实际上还是之前的代码。有一个小技巧是可以改完代码点运行，运行前会进行代码编译，运行开始就说明是新的代码了，这样做的好处是你可以确保代码是新的代码，但必须注意运行也会把没序列化的数据清除。 运行：点击运行按钮的时候，会进行数据的重置，我在某个 MonoBehaviour 的 Awake 方法里访问上面提到的类，每次都会有输出。但是运行还需要注意的是，Unity 点击运行会把没有进行序列化的数据丢掉，这时退出运行，之前在编辑器状态下设置好的数据就没了。序列化的数据，这里是指 MonoBehaviour 中访问修饰符为 public 的变量和拥有 SerializeField 这个 Attribute 的变量。 退出运行不会进行内存重置，但很重要 ，因为退出也相当于加载了场景，会执行 Awake 等相关函数，如果你有一些初始化函数在这时候执行，你需要注意它是否会影响到你。 ScriptableObject这个类看似很简单，但是第一次使用却花费了我很长时间来与其搏斗。这个类主要用来进行数据交互，它不需要挂在 GameObject 上，可以作为单独的数据存储来使用。在写编辑器扩展的时候使用它，有不少地方需要注意。 ScriptableObject 与 AssetScriptableObject 可以保存为 Asset，而且实际使用时发现，如果你不保存成 Asset，相关的引用就会在某些时候变为空。例如使用 ScriptableObject.CreateInstance 创建 一个 ScriptableObject 后，把它保存在容器里，然后函数结束。当你下次再用，就会发现这个引用变为 null 了。如果 ScriptableObject.CreateInstance 之后把这个 ScriptableObject 保存为 Asset，则没有问题。 删除 ScriptablObject Asset如果使用诸如 AssetDatabase.LoadAsset&lt;&gt; 之类的函数把 ScriptableObject Asset 加载进来，然后保存在一个 MonoBehaviour 的变量里，当你删除这个 Asset 时，这个变量也为空了。也就是说，如果是直接加载这个 ScriptableObject Asset，当 Asset 被删除，加载进来的对象也没了（我原本以为挂在物体上的数据还会保留 ）。 这个不注意可能会有一些致命的问题，例如你有个 ScriptableObject Asset，里面可能还有很多子 ScriptableObject Asset，策划想要用你的编辑器继续做上次没完成的工作，于是把上次保存好的 ScriptableObject Asset 加载进来进行操作，操作完毕后进行保存，可能会直接选择上次的路径，代码里可能会使用 AssetDatabase.CreateAsset 等方法，这实际上会覆盖原先的资源，也就是说之前的资源被删掉了。这时问题就来了，资源被删除后，Scene 中的数据也没了，这时保存代码执行，自然什么也保存不到。 解决方案是加载后使用 Instantiate&lt;&gt; 去复制出一个 ScriptableObject，之后都操作这个复制出来的，或者干脆用 ScriptableObject.CreateInstance 创建一个新的（要注意上面提到的问题，最好创建完后立即使用或者挂在物体上）。 枚举保存数据的时候，尽可能不要用枚举作为 key ，因为一旦枚举因为一些原因，数值有变化，数据可能取不出来。可以考虑转成字符串。参考了下 C# 的源码，枚举在进行 GetHashCode 的时候，貌似是用它的数值进行操作的。 结语这次暂时写这么多，再次希望不要有第二篇。以上如果有朋友知道更准确的原因，可以留言。感谢大家阅读。]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity 编辑器扩展 游戏开发 Unity序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么 Mipmap 会多占 1／3 内存而不是其他值？]]></title>
    <url>%2F2018%2F05%2F16%2F%E4%B8%BA%E4%BB%80%E4%B9%88%20Mipmap%20%E4%BC%9A%E5%A4%9A%E5%8D%A0%201%EF%BC%8F3%20%E5%86%85%E5%AD%98%E8%80%8C%E4%B8%8D%E6%98%AF%E5%85%B6%E4%BB%96%E5%80%BC%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！ 预备知识最基本的图形学基础和 Mipmap 基本原理。 概要Mipmap 会多占 1/3 内存在游戏渲染界可能是常识了，不过最初我在接触的时候也没多想，以为只是一个通过实际测量得来的经验值，如果有比现在常见的分辨率大很多的纹理，就会有不同的结果。但是最近在复习数学的时候（说来惭愧，与其叫复习不如说是重学，大学高数高代离散数分都靠考前一个礼拜突击才过的），突然想到了这个其实可以用数学来求解，无论纹理多大，Mipmap 所多占的内存都是一样的。 Mipmap 各级别尺寸想要用数学求解，必须先了解 Mipmap 各个级别的尺寸大小是如何确定的，正常来说，Mipmap 会生成很多级别，每一级别的宽高都是上一个级别的 1/2，也就是说面积为上一个级别的 1/4，直到最终只有 1x1 分辨率的大小。 举个例子，一张 1024 1024 的纹理，生成 Mipmap 后，会新产生 512 512，256 256，128 128，64 64，32 32，16 16，8 8，4 4，2 2，1 1 这几张不同纹理级别的纹理。可以手动计算一下，新产生的纹理大小总和是 349525 个像素，而原来的 1024 1024 纹理有 1048576 个像素，349525 / 1048576 约等于 0.33333302，也就是大约 1/3。 扩展到一般情况，需要用数学求解一下。 数学推导用错位相减法可以方便地求解： S = \frac{1}{4} + \frac{1}{16} + \frac{1}{64} + \cdots + \frac{1}{4^n} 4S = 1 + \frac{1}{4} + \frac{1}{16} + \cdots + \frac{1}{4^{n-1}} 4S - S = 3S = 1 - \frac{1}{4^n}我们不会去考虑 n 只有 1 的情况，这没什么意义，也很特殊。所以我们直接求 n 趋向于正无穷时的结果。 \lim_{n \to \infty}3S = \lim_{n \to \infty}1 - \frac{1}{4^n} = 1所以 \lim_{n \to \infty}S = \frac{1}{3}关于数学的一些想法数学确实是个很有意思的东西，这篇文章也是在我复习的时候想到的，这也印证了我的一个想法，长期不做数学题，数学思维就会退化，这篇文章的数学推导也不知道有没有不严谨的地方，以后还是要更加努力才行。]]></content>
      <categories>
        <category>图形</category>
      </categories>
      <tags>
        <tag>游戏开发 图形学 Mipmap 内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从纹理中生成法线贴图]]></title>
    <url>%2F2018%2F04%2F30%2F%E4%BB%8E%E7%BA%B9%E7%90%86%E4%B8%AD%E7%94%9F%E6%88%90%E6%B3%95%E7%BA%BF%E8%B4%B4%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！ 概要本为主要讲解生成法线贴图的基本方法，并在 unity 中进行实现和测试。 预备知识法线贴图和基本的图形学知识，基本的向量和极限的知识。 高度图或灰度图一张二维纹理有两个维度 u 和 v，但其实，高度(h)可以算第三个维度。有了高度，一张二维纹理就可以想象成一个三维的物体了。 先来考虑只有 u 方向的情况，如图所示， A 和 B 是纹理中的两个点， uv 坐标分别是 （0, 0） 和 （1, 0），上方黑线表示点对应的高度，那么显然，只要求出 u 方向上的高度函数在某一点的切线，就能求出垂直于他的法线了。同理， v 方向也是如此。也就是说，如果有纹理的高度信息，那么就能计算出纹理中每一个像素的法线了。 所以计算法线需要一张高度图，它表示纹理中每一个点对应的高度。 但其实并不需要求出每个纹理像素上 uv 方向各自的法线，只需要求出 uv 方向上高度函数的切线，再做一个叉积，即可计算出对应的法线了。 如果没有高度图，也可以用灰度图代替，灰度图就是把 rgb 三个颜色分量做一个加权平均，有很多种算法提取灰度值，这里用一个比较常用的基于人眼感知的灰度值提取公式。 1color.r * 0.2126 + color.g * 0.7152 + color.b * 0.0722 这个公式是由人眼对不同颜色敏感度不同得来的，这里无需过多计较，直接把提取出来的灰度值作为高度值即可。 计算方法当需要求一个点的函数图像切线的时候，只要求出该点的函数斜率即可，即是导数，这需要和它相临的点进行计算。显然，两个点越接近，结果越精确。所以有如下公式： h'(u) = \lim_{\Delta u \to 0}\frac{h(u + \Delta u) - h(u)}{\Delta u} h'(v) = \lim_{\Delta v \to 0}\frac{h(v + \Delta v) - h(v)}{\Delta v} 求出切线后，就得到了两个方向上的切线向量 $(1, h’(u)) 和 （1, h’(v)）$。之所以是这种形式的二维向量，是因为这里是按照 uoh 平面和 voh 平面分别计算的，具体的向量形式需要根据实际情况去组合。这里可以做一个优化，在求导数的时候公式里做了一个除法，因为法线最终会归一化，切线向量长度不影响叉积后的结果向量方向，所以其实可以直接把求导数时候的除法去掉，即直接将切线向量乘以 $\Delta u 和 \Delta v$，变为 $(\Delta u, h(u + \Delta u) - h(u)) 和（\Delta v, h(v + \Delta v) - h(v)）$。如果你觉得乱，没关系，后面看具体的代码就明白了。 接下来是将两个向量做叉积，叉积的顺序会影响计算出的法线的方向，这个要根据实际情况去决定。 实例这个例子使用 unity shader 去动态的生成一张纹理中每一个像素的法线，并当作颜色输出出来，最终在屏幕上会看到一张动态生成的法线贴图。将纹理放置成平行于屏幕的方向，如下图所示： 整张纹理处于世界空间 XOY 平面，并且朝向 -Z 轴（unity 使用左手坐标系，且 Z 轴朝向屏幕里）。 由于没有高度图，所以提取出灰度值来当作高度图，算法根上面描述的一样，函数名为 GetGrayColor。 1234float GetGrayColor(float3 color)&#123; return color.r * 0.2126 + color.g * 0.7152 + color.b * 0.0722;&#125; 然后可根据高度图的值来计算 uv 两个方向的高度函数切线。 12345678910111213141516171819float3 GetNormalByGray(float2 uv)&#123; // 代码后有详细的讲解 float2 deltaU = float2(_MainTex_TexelSize.x * _DeltaScale, 0); float h1_u = GetGrayColor(tex2D(_MainTex, uv - deltaU).rgb); float h2_u = GetGrayColor(tex2D(_MainTex, uv + deltaU).rgb); // float3 tangent_u = float3(1, 0, (h2_u - h1_u) / deltaU.x); float3 tangent_u = float3(deltaU.x, 0, (h2_u - h1_u)); float2 deltaV = float2(0, _MainTex_TexelSize.y * _DeltaScale); float h1_v = GetGrayColor(tex2D(_MainTex, uv - deltaV).rgb); float h2_v = GetGrayColor(tex2D(_MainTex, uv + deltaV).rgb); // float3 tangent_v = float3(0, 1, (h2_v - h1_v) / deltaV.y); float3 tangent_v = float3(0, deltaV.y, (h2_v - h1_v)); float3 normal = normalize(cross(tangent_v, tangent_u)); return normal;&#125; 上面代码分为 3 段，前两段为计算 uv 各自方向的高度函数切线，最后一段计算最终法线。 先看第一段，计算 u 方向的高度函数切线。首先，确定步长 $\Delta u$ 的大小。_MainTex_TexelSize 是 unity shader 内置的一个变量，保存着纹理大小相关的信息，是一个 float4 类型的值，具体为 (1 / width, 1 / height, width, height)。_DeltaScale 是一个控制步长缩放的变量，在这个例子中为 0.5，乘以 _DeltaScale 是用来控制法线生成的精确度的，就如之前所说，$\Delta u$ 越小，生成的法线就越精确。通常我们会向当前采样点两侧去采样，以获得更精准的结果，这个方法叫做中心差分法。然后可以根据步长分别取当前像素左右两侧的高度值（在这个例子里就是灰度值），在按照上面提到的计算方法计算切线即可。注释掉的代码是原始代码，下面没注释的是优化后的代码，这个也是上面提到的。 有一个问题是，为什么计算出来的切线向量是 (x, 0, z) 的形式，而不是其他？这是因为前面提到整张纹理是处于 XOY 平面的，而高度是第三个维度，因为 u 和 v 自然是按照 x 和 y 轴处理方便，所以高度 h 就按照 z 轴来处理了。 还有一个可能的疑问是，当 _DeltaScale 特别小的时候，取两侧的像素实际上都是单前像素，则高度差都是 0 了。但实际上这个情况只有在采样过滤方式为 point 采样时才会出现，具体采样过滤方式是如何处理的可以查阅其他资料。 同理，第二段可以计算出 v 方向的高度函数切线，两个切线向量，做叉积，再归一化，即可获得当前像素点表面的法线向量。叉积的顺序很重要，因为纹理是朝向 -z 轴的，所以一般来说会让法线也顺着表面所在的朝向，这就是为什么是 cross(tangent_v, tangent_u) 而不是 cross(tangent_u, tangent_v) 的原因。 现在将法线当作颜色输出出来看一下，当然不能直接输出，因为法线向量可能包含着负值，可能看到的都是黑色，所以需要转换一下，这个转换对于了解过法线贴图的读者应该很熟悉了。 1fixed4 color = normal * 0.5 + 0.5 直接输出这个 color，如下图所示： 看起来跟常见的法线贴图有些不一样，常见的是偏蓝色的那种。为什么是偏蓝色的呢，因为常见的法线贴图都是切线空间的，至于切线空间，可以看我这篇博客，讲解了切线空间是怎么计算的：切线空间(Tangent Space) 的计算与应用。 基于切线空间的法线贴图，z 也就是 b 通道的值都是 0.5 到 1，而 x 和 y 也就是 r 和 g 通道都是 0 到 1，所以看起来会偏蓝一些，当然不是绝对。而上面计算出来的法线贴图，由于叉积的顺序，z 分量是朝向 -z 轴的，所以 b 通道都是 0 到 0.5，不信可以用截屏工具看下颜色值。在这个例子里，想要变成切线空间下的法线贴图是非常简单的，只需要将 z 分量乘以 -1 即可， 12normal.z *= -1;fixed4 color = normal * 0.5 + 0.5 结果如下图： 根上一张图比，确实偏蓝一些了，但是依然不够蓝。这并不是因为这张纹理特殊，而是还有一些校正的步骤没有做。 在计算切线向量的时候，是直接用高度差和 $\Delta$ 值做计算的，这其实是不合理的，因为 $\Delta$ 是非常非常小的，一张 1024 * 1024 大小的图，$\Delta$ 只有 1 ／ 1024 = 0.00097656，但是高度差却是 0 到 1 之间某两个数的差，例如高度为 0.6 和高度为 0.2，正常来说是远大于 $\Delta$ 的，这就导致了切线向量很接近 -z 轴，计算出的法线就很接近于 xoy 平面了，这样就看起来有很多红色和绿色，因为 x 和 y 的分量更大。为了解决这个问题，需要引入一个 _HeightScale 变量，来控制高度差的比例。 12345678910float3 GetNormalByGray(float2 uv)&#123; ... float3 tangent_u = float3(deltaU.x, 0, _HeightScale * (h2_u - h1_u)); ... float3 tangent_v = float3(0, deltaV.y, _HeightScale * (h2_v - h1_v)); ...&#125; 当这个值为 _HeightScale 值为 0.01 时，法线贴图结果如下： 这张法线贴图看起来正常了，而且仔细观察可以发现，每一个砖块的上侧是偏绿的，因为 y 对应于 g，右侧是偏红的，因为 x 对应于 r。 可以不用中心差分法吗可以使用有限差分法，即不取像素两边相邻的点，而是只取一个方向上相邻的点与当前像素比较，这种方法想想也知道效果一般不如中心差分法的好。 除了高度差缩放，还有别的参数可以调节吗有，这里简单列举两个，因为修改都很简单，而且效果不适合这里讲的例子，所以不在本文实现了。 凹凸值图中每一个砖块，是凹进去的还是突出来的呢？要改变这个属性，只需要调整法线 xy 的正负即可，就会改变原有的凹凸方向，稍微想象一下应该就能想出来。 粗糙度可以在原来的法线题图基础上，进一步修改法线贴图的粗糙度。其实之前的高度差缩放，也是处理粗糙度，但是当你有一张已经生成好的法线贴图时，想修改就需要做额外的处理了。也很简单，对法线的 xy 分量进行缩放，然后再重新计算 $z = \sqrt{(1 - x^2 - y^2)}$) 即可。 加上光照法线是为了光照服务的，所以这里再演试一下加上一个平行光之后的漫反射的效果，并与没加法线贴图的效果做一下对比（默认法线为 -z 轴方向）。 首先是没有法线贴图的情况。 1234567891011fixed4 frag (v2f i) : SV_Target&#123; float3 normal = float3(0, 0, -1); fixed4 texColor = tex2D(_MainTex, i.uv); float diffuse = saturate(dot(normal, normalize(_WorldSpaceLightPos0.xyz))); fixed4 color; color.rgb = texColor.rgb * diffuse *_LightColor0.rgb; return color;&#125; 最终的结果如下图所示： 这是将光源绕 x 轴和 y 轴都旋转了 60 度并且使用默认法线得到的 diffuse 结果，和原来没有光照的原图比较，有了明暗的变化，但依然只是一张平坦的图。 接下来是使用了上面算法动态生成法线贴图的情况。 12345678910111213fixed4 frag (v2f i) : SV_Target&#123; float3 normal = GetNormalByGray(i.uv); // normal.z *= -1; normal.xy *= _Camber; fixed4 color; fixed4 texColor = tex2D(_MainTex, i.uv); float diffuse = saturate(dot(normal, normalize(_WorldSpaceLightPos0.xyz))); color.rgb = texColor.rgb * diffuse *_LightColor0.rgb; return color;&#125; 注意这里的 normal.z 不再乘以 -1 了，因为这个例子一切都是在世界空间下计算的，正常情况下可能在切线空间算效率会更高一些，但这并不是本篇文章的内容。最终输出的结果如下图所示： 可以看到，整张图有了明显的立体感，砖块也显得粗糙了，与之前有了极大的效果提升。再仔细观察可以发现，每个砖块左边和上边都被照亮，右边和下边都变暗了，这正符合平行光的旋转角度，所以光照结果是正确的。 最后的工作最后的工作就是把生成的法线贴图保存到硬盘上，这一步只需要调用引擎的相关 API 把渲染出来的法线贴图保存为资源即可，也可以直接在 cpu 上操作去生成一张，但这么做就不方便用实时光照去查看效果了。]]></content>
      <categories>
        <category>图形</category>
      </categories>
      <tags>
        <tag>游戏开发 图形 法线贴图 算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对 Gamma 校正的个人理解]]></title>
    <url>%2F2018%2F02%2F24%2F%E5%AF%B9-Gamma-%E6%A0%A1%E6%AD%A3%E7%9A%84%E4%B8%AA%E4%BA%BA%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！如果在第三方阅读发现公式等格式有问题，请到原文地址阅读。 为什么要写这篇文章Gamma 校正，看起来似乎是一件很简单的事情，做一次幂运算就可以了，但是如果深究的话，就会发现 Gamma 校正是个有点容易让人混乱的东西，每个人的解释可能都有一些不一样。最主要的是，Gamma 值在不止一个地方会用到，而这些地方应用的时候还或多或少有一些关联，所以深究 Gamma 校正的时候，非让容易令人感到困惑。我在读了一些资料，自己进行了一番理解之后，打算写一篇文章记录和分享一下自己的所得。 Gamma 是什么物理亮度物理亮度，就是真实世界中的亮度，可以认为是由光子数量来决定的，并且亮度与光子数量成线性关系，也就是说物理亮度存在于一个线性的空间中，物理亮度每提升 0.1，亮度的增加都是相同的。先说明这一点也是为了避免读者在后面的文字中对提到的物理亮度与其他东西感到混淆。 Gamma 的由来Gamma 的由来，说法是不统一的。 部分人认为是由于早期 CRT 显示器的问题，即输出的亮度和输入的电压并非线性关系，而是近似 2.2 次幂的关系，导致进入人眼的亮度要比计算机上存储的亮度要低。例如，计算机上存储的亮度为 0.5，经过显示器调整后变为 0.5 的 2.2 次幂，即 0.218。为了让进入人眼的亮度与计算机中存储的值相同，需要在显示器调整前将亮度变为自身的 1/2.2 次幂，即 0.73，这样在经过显示器的调整，进入人眼就是 0.5 了，也就是说，Gamma 校正可以补偿由于显示器造成的亮度下降。这里需要注意的是，2.2 这个值是一个近似值，或者可以说是一个标准，实际上可能会有不同，现在的显示器甚至可以调节。 还有一种说法是，人眼对不同亮度的敏感程度是不同的，对暗部的敏感要高于亮部（这个是没错的）。而存储颜色的空间是有限的，例如常用的 RGBA32 格式，每个颜色通道都只有 8 位，只能存储 256 种亮度，所以基于人眼感知的原因，用更多的空间存储更多暗部的颜色是更合理的。人眼感知到的中间亮度值大概是 0.18，换算到 0.5 大约是 pow(0.18, 0.4042)，也就是说大约可以用 0.4042 这个指数（但是也有说通过人为测量，指数定到 0.45 的，这里不必纠结，因为本身就是近似值，每个人感知的也不一样），来计算亮度最终变换后的结果，以存储更多暗部的亮度值（后面会详细讲解为什么这么做可以存储更多暗部的亮度值）。当然显示的时候，依然需要把这个亮度再变换到幂运算之前的结果，以显然原本的颜色，不过实际上并不需要这么做，因为这里有一个美妙的巧合，那就是我们用来提高暗部存储范围的指数，恰好和测量出的显示器调整输出亮度的指数近似为倒数，也就是说，什么也不用做，显示出来的自然就是原本的颜色。 以上就是 Gamma 的两个由来。第一个主要是由于显示器特性，所以我们需要提高 01 之间亮度，以达到让显示器输出原本的颜色；第二个是由于存储有限，所以要提高暗部的存储区域（其实也是提高了 01 之间的亮度），恰好又能利用显示其特性恢复成原本的颜色。 实际上并不需要太关心哪种说法是真正的起源，其实这两种说法都是正确的，只需要明白 Gamma 是什么即可，可以通过一张图来直观的解释： 横坐标为输入值，纵坐标为输出值，中间的点线是物理亮度值，也是线性空间中的值，下方的实线是经过显示器校正的曲线，而上方的虚线是我们提高亮度或者说增大暗部存储范围后的曲线。 提高暗部亮度值存储范围的原理sRGB 空间有一个很重要的作用，就是我们用来存储颜色的媒介往往不够存储很多细节，比如常用的 RGBA32，每一个通道只有 8 位，即 0 到 255，只能存 256 个级别的亮度，这会丢失很多物理世界里的真实信息。那么如何在不增加存储范围的情况下，尽可能保留更多的物理信息呢？答案是，通过 Gamma 校正，把较暗的部分的存储范围放大，当然这会导致较亮的部分丢掉一些细节。这么做的依据是前面提到的人眼对暗部更敏感，所以应该用更多的范围去存储较暗的部分，而亮的部分，即使丢失掉一些细节也没关系，因为人眼可能并不会感知到。 通过上面的图可以看到，在物理世界中，假设摄像机采样到的亮度为 0.218，如果就这么直接存储，那么采样的所有 0.218 以下的亮度都只能保存在 0.218 这个值以下，换成 8 位二进制表示只有 256 乘 0.218 等于 55 个级别。而 0.782 到 1 的值直接保存的话，也是 55 个级别，这样就造成了浪费，因为我们对 0 到 0.218 这个范围的敏感程度要大于 0.782 到 1 这个范围，而这两个范围都用 55 个亮度级别去表示，这就会使得我们本来可以感觉的更多的暗部的细节，但现在感觉不到了。 当我们将物理世界中采样的亮度变为它的 0.45 次幂，也就是上图中上方的虚线，情况就会不一样。0 到 0.218 这个范围会变为 0 到 0.5，也就是说我们可以用 128 个级别去存储 0 到 0.218 这个范围，这样我们可以感受到 128 个级别的亮度，而 0.782 到 1 经过 Gamma 校正后的范围是 0.9 到 1，也就是只有 26 个级别。这符合我们人眼的特性，前面提到过，人眼感知物理亮度在暗部更敏感。 现代显示器还需要 Gamma 校正吗前面提到，CRT 显示器会有这个问题，那么现代显示器呢？其实现代显示器就算没有 CRT 这个问题，也会保留这个特性，原因可能是要兼容老的 CRT 显示器，反正就这么一直保留下来了。 线性空间和 sRGB 空间Gamma 校正涉及到两个颜色空间，即线性空间和 sRGB 空间。 线性空间线性空间就是上图中中间的直线，而这条直线也是物理世界中的亮度值变化。 sRGB 空间sRGB（standard RGB）是微软和惠普一起定制的颜色格式，在 sRGB 格式下，Gamma 值为 2.2，对应上图中上方的虚线。具体的 sRGB 和 线性空间转换的公式为： sRGB(x) = \begin{cases} 12.92 x, & x 0.0031308 \end{cases}\\[2ex] x \; 为\text{线性空间中的颜色}\\[4ex] linear(x) = \begin{cases} \frac {x} {12.9}, & x 0.04045 \end{cases}\\[2ex] x \; 为\text{sRGB空间中的颜色}但一般我们自己计算的时候，都会直接用简化形式，即变为 2.2 次幂 或者 1/2.2 次幂。 颜色空间的应用Gamma 校正除了可以补偿亮度的损失之外，它在图形学中一个非常重要的作用是，它使得我们在计算光照的时候使用的数据是正确的。 通常情况下，设计师制作好的图片一般都是基于自己观察到的，也就是基于物理世界的亮度值，因为有显示器调节降低亮度的缘故，实际上在计算机中存储的是观察到的亮度值的 0.45 次幂（以下 Gamma 值都算作 2.2， 1 / 2.2 约等于 0.45），因为物理世界是线性空间的，所以这种情况下计算机中存储的值就是 sRGB 空间。如果用 sRGB 空间的值计算光照，则光照算法实际上是有些问题的。 举个例子，设计师制作了一张亮度值为 0.5 的图（0.5 指的是计算机中存储的原图亮度，也就是 sRGB 空间），经过显示器调解后，亮度变为 0.218。这时如果使用名为“将亮度变为原来的 2 倍”的算法时，如果直接将计算机中的 0.5 乘上 2 ，即为 1，再经过显示器调解，输出出来的亮度值还是 1 （因为是 1 的 2.2 次幂）。从 0.218 到 1，亮度变为之前的 4 倍多，这并不是我们预期的（注意我并没有说这样的效果一定不好，只能说不是我们预期的）。所以我们需要先把计算机中的亮度值还原成线性空间的，也就是将 0.5 变换为线性空间的值 0.218，再乘 2 变为 0.436，此时依然是线性空间中。不过这时候不能直接输出，因为显示器会把 sRGB 的值变换到线性空间，如果计算机中存储的是线性空间的值，那么把线性空间的值再进行一次变换，就是错误的，所以我们需要再把 0.436 这个线性空间的值再重新变换到 sRGB 空间，即 pow(0.436, 0.45) 约等于 0.688，最后再经过显示器的调解后，变为 pow(0.688, 2.2) 约等于 0.439，这样观察到的物理世界亮度基本就是原来的 2 倍了（原来的物理世界中的亮度为 0.218）。 颜色空间对游戏开发的影响设计师在制作纹理的时候，最方便的方法自然是自己看到什么就是什么，也就是上面说的 sRGB 空间。而如果因为一些原因，设计师直接出了一张线性空间的图，那么在计算时不需要进行转换，但是输出的时候，需要进行一次 Gamma 校正，转换到 sRGB 空间，这样输出到物理世界的值就是计算机纹理中存储的线性空间的值了。 颜色空间也会影响纹理的采样，颜色的 blend 等，这里不多讲了，网上的资料很多，本文重点还是想讲解 Gamma 校正的一些相关原理。 关于纹理颜色空间的选择那什么时候需要线性空间呢，什么时候需要 sRGB 空间呢？ 我个人认为的是，表示颜色的纹理应该选择在 sRGB 空间，因为这可以改变不同明暗的颜色的存储范围，使其更符合人眼特性。而一些表示纯数值的纹理，就直接选择线性空间的值即可，不需要再换转了，因为他们本身就是用于计算的。比如一张表示 Phong 光照模型中物体镜面反射程度的镜面反射贴图，就直接选择线性空间的值即可，采样后就直接可以参与计算了。但这里说线性空间不一定准确，因为设计师在制作镜面反射贴图的时候，可能也是直接基于自己观察到的亮度值，所以这个值也可以说是 sRGB 空间的。这个可能还是需要注意的，因为不同引擎可能对这个有不同的叫法，读者重点掌握这个值可以采样出来直接用于线性空间的光照计算即可。 总结这篇文章的目的主要是梳理 Gamma 校正到底是什么，实际使用时，Gamma 校正还有一些地方需要注意，尤其是在使用纹理和进行 blend 的时候，有机会我也会进行一些探讨。 以上关于 Gamma 校正相关的解释都是我个人的理解，如果有不对的地方，还请指出。 感谢阅读。 参考资料 Learn OpenGL — Gamma Correction wikipedia — Gamma correction wikipedia — sRGB Gamma校正与线性空间 What is the purpose of gamma correction in today’s screens and how does it relate to graphics and photography? 知乎 — 色彩校正中的 gamma 值是什么？ 我理解的伽马校正]]></content>
      <categories>
        <category>图形</category>
      </categories>
      <tags>
        <tag>Gamma Gamma校正 图形 游戏开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Global Game Jam 2018 经历分享]]></title>
    <url>%2F2018%2F01%2F29%2FGlobal_Game_Jam%20%E7%BB%8F%E5%8E%86%E5%88%86%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！ 关于本文很久以前就听说过 Global Game Jam（以下简称 GGJ），但因为一些原因没有参加过，很高兴这次终于能来参加这样有趣的活动。在这里先附上我们这次做的游戏的几个相关链接，有兴趣的朋友可看看。 我们的 b 站视频通关链接，up 主是我们的队长。 b 站视频通关 还有我们的 GGJ 2018 的页面。 中文站原站 别怕，文章不是很长，后面图不少。 关于 Global Game JamGGJ 是一个大型的线下独立游戏节，全球各地都有站点，今年我没记错的话有 100 多个。全世界的独立游戏开发者在此时一起参与，围绕同一个主题，组队或者单人在 48 小时内按照自己的想法去开发游戏。对于游戏本身几乎没有任何限制，主题也很开放，所有人都可以充分发挥自己的想象力，去制作一个自己喜欢的游戏。 值得注意的是，这个全球一起参与是有时差的，比如 15 点开始，那么每个站点就都是当地 15点开始，所以一些站点就会更早得到主题，而开发者们需要在最后一个站点公布主题之前对主题进行保密。 第一天主题公布大概三点半左右，我和同事们一起到了北京站会场进行签到，这也是我们这次的队伍的大部分成员。 之后就在会场内坐着观看暖场视频并与其他人进行交流。据我观察，大部分可能都是学生，这也比较符合常理，学生更有热情和时间。过了没多久，本次活动终于正式开始了，主持人也就是 CIGA 的创始人在进行了一段讲话后，就开始播放主题视频。 本次的主题和去年的主题有很大相似的地方，去年是 Waves ，今年是 Transmission ，他们都有传输方面的意思，而今年的主题，除了传输这类意思，还可以理解成传动，当然这种开放式的主题怎么理解都有道理。 主题公布以后，北京站还有一个额外的活动，请了乐元素的一个制作人来进行一场有关商业游戏和独立游戏的分享，这之后才是组队环节。 组队报名 + 赶去参加公司的年会然而我们公司的年会和这次活动的时间重合了，有一些事情得在年会上去做，所以当组队报名开始后，我和同事们立即登记好了信息，便赶去了年会地点。 由于提前就组好了队，所以我们可以直接进行队伍报名，我们的组号是 02，很靠前，由于我们想做一个像素游戏，我们的队名就叫做 Bit Bit 。赶往年会途中被同事告知我居然中了奖23333333。（请注意这是描述性词语，不是我中了 23333333 数额的奖金） 8点左右到了年会，必不可少的与各个领导和同事轮番敬酒／可乐／雪碧／芬达／水／空气，回到会场时已经11点多了。 由于我们的美术小伙伴暂时还并不是我们的同事，所以没有办法只能让他一个人先在会场里与其他人进行交流和等我们回来了（这里给美术大大点赞！后面试玩很多人都赞扬我们的美术）。 由于已经喝了一些酒，虽然还算清醒，但是感觉已经不适合去会场了，所以我们打算在提前订好的酒店里商量做什么，然后大家就去睡觉，第二天正式开工（喝完酒写代码还不一堆 bug）。 决定游戏开发计划这大概是整个过程中最重要的一环了，毕竟游戏的设计直接决定了游戏的质量。 游戏方向首先我们进行且仅进行了一轮头脑风暴式的交流，每个人说出自己从主题公布到现在的想法，但最后大部分想法都被直接否决了，不是这些想法不好，而是这种活动，创意很重要，对于 Transmission 这个主题，我们直观上想到的传送带，传输光，连接物体进行传输这些具体的概念应该都是很容易被别人想到的，所以可能会让人觉得创意不足，而那些抽象的概念，可能就不会有那么多人想到，就更会让人觉得新奇。在我们之前的讨论里，我们队伍里的策划小伙伴有一个关于 纸飞机 的想法，纸飞机是一个具体的东西，但是纸飞机本身就经常被用来作为抽象概念的载体，比如爱情，思念等，加上 Transmission 这个主题，可以做一个用纸飞机传达情感的游戏，即表面上用物理概念下的纸飞机飞来切合主题，然后深层次上用传递情感来升华这个主题。 除此之外，我们还保留了两个想法，讨论的时候是这三个想法一起讨论的，因为要考虑时间和难度的问题。有一个想法在技术上很容易实现，所以被我们否决了，毕竟我们也是专业团队，感觉如果做的特别简单，可能自己心里也过不去。另一个想法在一些设计问题上我们暂时没有想到特别好的思路，所以也否决了。 最终我们决定做纸飞机相关的想法，然后为了避免意外，我们把那个简单的游戏作为候补，如果前一个游戏出现重大问题，我们也能在短时间内坐制作一个可以给别人玩的小游戏。 内容细节游戏方向决定后，我们开始讨论游戏的细节（为了文章的流畅度，这里要说明一下，有一些细节是在第二天我们正式开始做的时候决定添加的）。纸飞机也是飞机，自然是要飞的（废话），这也是表层的 Transmission ，体现在玩法上就是飞机要从起点飞到终点，到达终点就可以进入下一关。这种玩法自然飞行过程中要有障碍物，所以我们在场景中摆放了很多建筑，这些建筑都带有 死亡碰撞体 ，纸飞机碰到游戏就会失败。而纸飞机是没有动力的，我们需要给它添加一个力，让他可以飞到终点，这个我们决定使用物理系统来对纸飞机进行推动，体现在玩法上就是吹风机对纸飞机的吹动。整体上来说，玩家需要摆放吹风机，从而影响飞机的飞行路线，最后让飞机抵达终点。这就是整个游戏的核心玩法。 决定了表层后，就轮到深层了。纸飞机可以用来传达情感，这也是深层的 Transmission 。传达的过程中可能会遇到挫折，就好比人在传达爱意的时候，可能会遇到各种失败，而经过不断的努力尝试，才能传达到爱慕之人的心里。所以不仅我们的关卡也被设计成越来越难，在表现形式上也增加了狂风和雷雨的天气（时间原因只做了四个关卡，但是策划小伙伴搭的场景很棒），越到后面天气越恶劣，在这些关卡里绝大部分玩家需要反复不断的尝试，才可能成功，我们希望能让玩家体验到，情感的传达可能很困难，需要不断努力。 艺术风格来之前，我们已经确定了我们采用像素风格来作为游戏的艺术风格，而在此基础上，我们需要决定游戏的背景设定，是现代，还是古代，是充满科技感的未来，还是荒凉凄冷的末世。我们的美术大大很给力，我们所提出的风格想法他都能 hold 住，当然在这方面我们只能提供意见，如果美术大大不同意，那这个风格就会被否决。 末世这个题材，和情感这个略微暖一些的题材放在一起，莫名有一种反差之美，最终我们也决定了末世的背景设定，即末世加像素的艺术风格。 明确分工当天晚上的最后，我们开始决定分工。其实我们也并没有很明确的进行分工，就是简单交流了一下技术方案，设计方案，明确了下每个人大概的工作内容。在实际制作过程中，大家都会或多或少的做一些别的工作，例如 订外卖，取外卖，解决多出来的吮指原味鸡，寻找凌晨两点在黑暗的大楼里不小走失的同伴 等等。 睡觉时光飞逝，岁月如梭，终于到了睡觉的时间。洗漱完毕后，劳累了一天，我们很快就进入了梦乡（然而我并没有做梦）。 第二天第二天，我们早上来到会场，发现前一天占领的桌子已经被来得更早甚至没走的人占领了（所以大家尽量早点去），于是我们在会场里又拼凑了几张桌子，开始了正式的开发。 由于很多东西都提前定好了，还有很多学生队伍不知道或不会使用版本控制，所以我们开发的速度还算是相对比较快的，主要是已经有几年的游戏开发工作经验了（我个人算上实习是两年半多一些，队里其他人大部分都比我多），在很多问题上能比较快的解决。 独立游戏大神确实是有的，从外形上再到作品上都能体现出来，也有本身就在网上有知名度的大神来参加，很多人从发型上就能看出来是搞艺术设计的，当然也有很多也能看出来是学生。 这一天我们基本完成了整个游戏流程和核心玩法，还剩一些 bug 和 细节打算在最后一天去解决。这一天虽然中间有闲逛的时间，但是整体还是很紧凑的，我开玩笑说这个游戏要是在公司里可能需要排两个礼拜的工期，果然 Deadline 是第一生产力。其实这一天倒没那么多可说的，因为一天基本都在开发，一直从上午10点开发到半夜快3点，虽然很累，但是内心其实是很快乐的。 第三天最后的冲刺终于到了最后一天，这一天下午我们要完成产品，准备试玩，并上台演示。游戏还剩一些 bug 没解决，细节还有一些没做完，这些都要在下午 3 点前搞定。虽然游戏在昨天已经能玩了，但是我们还是希望能把游戏的完成度提高。 我们要做的大概有：设计好关卡的难度和特效等细节，做好返回和继续的流程，提高一些游戏内用户体验的东西，增加通关后 all clear 场景并用动画展示开发人员名单，制作完 all clear 场景的通关画面和动画，增加场景切换动画，找到并添加多个 bgm，重写背景移动的功能（周六早上我花了10分钟用 shader 移动 uv 来完成这个功能，然而发现这个做法并不适应我们之后的需求，在花了很长的时间兼容需求但无法完美解决之后，最终还是在周日早上又花了 10 分钟用另一种方法完美实现了），修复所有已知的bug，增加若干场景内物件的动画，还有一些东西暂时想不去来了。这些东西要在上午 10 点多到下午 3 点前做完，开发时间还是有点紧张，不过最后还是都顺利完成了，这得益于大家的专业技能和都想把游戏做好的心。 现场试玩开发截止后，是短暂的试玩环节，我们的游戏相对来说有较高的完成度（反正玩家是这么说的）并且艺术风格看起来也很不错，吸引了很多人来玩，也有官方的美女来用手机在直播平台进行直播（频繁上镜），并且把整个游戏从开始到结束加上队长的实时讲解都完整的播了出来（不知道能不能找到录播），最后还配合 all clear 场景的开发人员介绍动画把小伙伴们都介绍了一遍。 从大家的反馈来看，一个是完成度相对较高（毕竟只有48小时，我们这个也算挺高的了），另一个是艺术风格很令人喜欢，尤其是对于女性玩家来说。 我也去试玩了一些其他队伍的游戏，大家的想法都挺有意思的，跟他们交流，能收获不少新思路。 展示短暂的试玩结束后，到了最后的展示的环节。我们是第 2 组，所以观众都在。第一组做的一个模拟氪金抽卡的游戏，有点恶搞的意思，但是展示效果很欢乐，本来想去玩玩，但是后来找不到了，之后就是我们组了。 展示我们的游戏我们队的队长一边玩一边讲述这个游戏的开发思路，为什么要做这个，每一关为何这么设计，我们要表达的是什么。展示前也一一介绍了团队的成员。游玩过程中配合 bgm 和像素末世场景，加上队长的讲解，相信是能给观众带来一定的思考的。 通关展示完毕，通关成功！（下图少了一个小伙伴的证书） 观看别人的游戏和与别人交流展示完成后，我们就在观看别人的展示，以及和其他人交流并且继续提供试玩。展示环节有很多非开发者来观看，貌似大多都是发行方面的人。喜欢我们游戏的人还是不少的，也有很多人和我们交流他们对我们游戏的想法，给我们提供了一些建议。看到别人喜欢自己的游戏，大概是对于一个游戏开发者最好的褒奖吧。 出乎我意料的是，有不少队伍都选择了单机多人对战游戏，我本以为在这样的活动中，选择纯单机是一个更好的选择，但是这些独立游戏开发者着实给我上了一课。 感受第一次参加这种活动，感受很多。我不仅见识了国内其他游戏开发者的热情，也看到了很多人很棒的点子，并且为之努力的认真劲。自己从小时候起就梦想长大后能成为一名游戏开发者，能开发出让大家觉得好玩的游戏，也是这种理想，让我一直保持初心，不断进步。 刚入行时国内游戏环境很不好，大量劣质换皮手游充斥着市场，能让人眼前一亮的国产游戏少之又少。随着玩家对游戏的认知越来越广，对游戏的要求也随之越来越高，虽然很多公司死掉，但也有很多好的游戏团队因为玩家对游戏品质的追求提升而得以存活，不至于像之前完全被稀释掉。近年来国产手游也偶尔有大放异彩的时刻，而更好的消息是，国产独立游戏的关注度越来越高，好游戏的曝光率也随之增加，这不仅仅只是对于独立游戏圈的好消息，也说明整个国内游戏行业从换皮买量就能赚钱逐渐地往注重游戏品质转移，只不过目前这类高皮质的游戏多见于独立游戏。单机游戏就不多说了，在所谓的 氪金手游 上，收入居高的也大多是玩法或者艺术体验至少有一样方面做的很好的。 我也很庆幸自己在工作中能结识这些很棒的同事，也很庆幸现在做的项目也是自己本身就感兴趣想做的游戏，更庆幸的是自己身在一个热爱游戏想做出好游戏的团队。 人生苦短，年轻时抓紧时间去追求自己的理想，才不至于老去时回首往事，尽是些遗憾。 希望热爱游戏开发的小伙伴们，都能不忘初心，做出好的游戏。]]></content>
      <categories>
        <category>独立游戏</category>
      </categories>
      <tags>
        <tag>GameJam GGJ 游戏开发 独立游戏 游戏设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[切线空间(Tangent Space) 的计算与应用]]></title>
    <url>%2F2017%2F11%2F28%2F%E5%88%87%E7%BA%BF%E7%A9%BA%E9%97%B4-Tangent-Space-%E7%9A%84%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！如果在第三方阅读发现公式等格式有问题，请到原文地址阅读。 原文地址 概要本篇文章主要讲解计算机图形学中切线空间是如何计算的，且会以法线贴图的例子来验证切线空间是否计算正确，以及展现切线空间的用途. 本文需要读者掌握一定的 3D 坐标空间变换和简单光照相关的知识，以及法线贴图的基本知识（但切线空间不仅仅只用于法线贴图）。 认识切线空间什么是切线空间切线空间 (Tangent Space) 与 世界空间 (World Space) 和 观察空间 (View Space) 一样，都是一个坐标空间，它是由顶点所构成的平面的 UV 坐标轴以及表面的法线所构成，一般用 T (Tangent), B (Bitangent), N (Normal) 三个字母表示，即切线，副切线，法线， $T$ 对应 UV 中的 $U$, $B$ 对应 UV 中的 $V$，下图是切线空间的示意图： 这里可能会有一个疑问，就是为什么 $T$ 对应 UV 中的 $U$, $B$ 对应 UV 中的 $V$ 。理论上，只要 $T$ 和 $B$ 垂直且都位于三角形的平面内，就可以达到使用切线空间的目的，因为这样我们总可以把所有需要的数据变换到同一个坐标空间下，但由于我们知道 UV 坐标的值，所以用 UV 坐标来对应 $T$ 和 $B$ 计算出数据了。 为什么要有切线空间要理解为什么要有切线空间，可以从法线贴图入手。众所周知，绝大部分的法线贴图，颜色都是偏蓝色的，这是因为法线贴图中存储的法线向量大部分都是朝向或者接近 z 轴的，即 $(0, 0, 1)$，换算到 RGB 中，就是偏向蓝色，即 $(0.5, 0,5, 1)$ (后面的 Shader 中有算法)，这种贴图就是切线空间 (Tangent Space)下的贴图。这显然存在一个问题，想象一个位于世界坐标原点且没有进行任何变换的立方体，表面法线方向就有 6 个，因为有 6 个不同朝向的面（确切的说，可能是 12 个面，因为一个矩形一般由两个三角形组成），而且每个面完全相同，所以这时候我应该只需要一个面的法线贴图就可以了。但其实这时再用这种偏蓝色的法线贴图就不行了，因为立方体的上表面在世界空间的法线方向为 $(0, 1, 0)$，而在法线贴图中采样出来的法线基本都是接近于 $(0, 0, 1)$ 的，使用错误的法线会得到错误的光照结果。所以这时候需要做一张包含立方体所有面的法线信息的法线贴图，也就是模型空间 (Object Space)下的法线贴图，而这种贴图看起来就不单单是偏蓝色了，而是包含了多种颜色。 这样看起来好像也没什么问题，但其实用切线空间下的法线贴图要比用模型空间下的法线贴图要有一些优势： 可以复用：比如上文提到的立方体，如果每个面都完全相同，则可以只制作一个面的法线贴图，然后就可以复用到所有面上，类似的复用需求还有很多，这可以减小内存占用和包体大小。 纹理可以压缩：因为切线空间下，一般来说法线方向不会是朝向表面内部，即法线贴图中的 z 值不会是负数，而我们使用的法线又是归一化的，所以完全可以根据 x 和 y 的值来推导出 z 的值，所以贴图中只需要存储 x 和 y 的值即可，可进行纹理压缩。 待补充 综上所述，一般的法线贴图都是使用切线空间的，而直接使用切线空间下的法线贴图又会出现之前提到的立方体的那个问题，所以我们在使用前需要先进行切线空间相关的变换，把所需要的数据变换到同一个坐标空间下再进行计算（可以全部变换到世界空间也可以全部变换到切线空间）。 切线空间的计算求切线和副切线要进行切线空间相关的计算，需要先求出构成切线空间三个轴的单位基向量，然后就可以构造出从切线空间变换到世界空间的矩阵，从而进行之后的计算。 切线空间的计算可以通过前面的示意图来理解，这里为了方便，再放一次： 设： \Delta U_1 = U_2 - U_1 \Delta U_2 = U_3 - U_1 \Delta V_1 = V_2 - V_1 \Delta V_2 = V_3 - V_1则由图和共面向量基本定理可知： E_1 = \Delta U_1 T + \Delta V_1 B E_2 = \Delta U_2 T + \Delta V_2 B \Rightarrow (E_1x, E_1y, E_1z) = \Delta U_1(T_x, T_y, T_z) \; + \; \Delta V1(B_x, B_y, B_Z) \Rightarrow (E_2x, E_2y, E_2z) = \Delta U_2(T_x, T_y, T_z) \; + \; \Delta V2(B_x, B_y, B_Z)观察这两个等式，我们发现这其实可以写成矩阵乘法的形式，如下所示： \begin{pmatrix} E_1x & E_1y & E_1z \\ E_2x & E_2y & E_2z \\ \end{pmatrix} = \begin{pmatrix} \Delta U_1 & \Delta V_1 \\ \Delta U_2 & \Delta V_2 \\ \end{pmatrix} \begin{pmatrix} T_x & T_y & T_z \\ B_x & B_y & B_z \\ \end{pmatrix}如果你求解一下等号右边的矩阵乘法，你就会发现，他就是我们在上面得到的等式。根据这个矩阵形式的等式，我们不难求解 $TB$ 矩阵，只需要两边同时左乘 $\Delta U \Delta V$ 的逆矩阵，再进行计算即可,步骤如下： \begin{pmatrix} \Delta U_1 & \Delta V_1 \\ \Delta U_2 & \Delta V_2 \\ \end{pmatrix} ^{-1} \begin{pmatrix} E_1x & E_1y & E_1z \\ E_2x & E_2y & E_2z \\ \end{pmatrix} = \begin{pmatrix} T_x & T_y & T_z \\ B_x & B_y & B_z \\ \end{pmatrix}逆矩阵的计算公式为 矩阵的行列式的值的倒数再乘以它的伴随矩阵 (Adjugate Matrix, 如果对这些概念不熟悉需要读者自行查阅），其实伴随矩阵的求解并不容易，不过 二阶矩阵的伴随矩阵 有一个简单的公式，即 主对角线的元素互换，副对角线的元素乘以 $-1$ ，所以最终结果如下所示： \begin{pmatrix} T_x & T_y & T_z \\ B_x & B_y & B_z \\ \end{pmatrix} = \frac{1}{\Delta U_1 \Delta V_2 - \Delta U_2 \Delta V_1} \begin{pmatrix} \Delta V_2 & -\Delta V_1 \\ -\Delta U_2 & \Delta U_1 \\ \end{pmatrix} \begin{pmatrix} E_1x & E_1y & E_1z \\ E_2x & E_2y & E_2z \\ \end{pmatrix}似乎我们还缺少 $E_1$ 和 $E_2$ 的信息，但其实这个信息是已知的，因为他们就是三角形的两个边，而三角形的顶点坐标是我们知道的，所以求出 $T$ 和 $B$ 所需的数据我们都已经有了，只需要代入公式就可以了。 设： ratio = \frac{1}{\Delta U_1 \Delta V_2 - \Delta U_2 \Delta V_1}则： T_x = ratio * (\Delta V_2 E_1x - \Delta V_1 E_2x) T_y = ratio * (\Delta V_2 E_1y - \Delta V_1 E_2y) T_z = ratio * (\Delta V_2 E_1z - \Delta V_1 E_2z)$B$ 也可以如此求解，但其实只需要用 $T$ 和 法线向量 叉乘 即可。 归一化因为 $E_1$ 和 $E_2$ 是用顶点坐标表示的，而 $U$ 和 $V$ 是纹理坐标，他们的坐标单位是不同的，所以我们求出的结果自然不太可能是已经归一化了的，而我们使用坐标空间转换矩阵的时候需要的是归一化的坐标，所以我们需要进行归一化。 法线贴图的例子本节将以一个法线贴图的例子，来展示切线空间是如何工作的，在这个例子中，我只计算了漫反射等颜色（因为除了法线贴图外我只找到一张漫反射的贴图，但足够演示用了，不过光照效果看起来未必会很好），下面两张图是我使用的漫反射贴图和法线贴图： 计算顶点数据为了方便展示，我准备了一个立方体的顶点数据，一共有36个顶点（6个面，每个面2个三角形），为了这篇文章的编写方便，我采用直接绘制顶点而非索引的方式，并且之后的一些计算会有些暴力。 36个顶点数据如下所示，每一行分别为顶点坐标（3个），法线向量（3个），以及纹理坐标（2个），每6行为一个面。 12345678910111213141516171819202122232425262728293031323334353637383940414243float vertices[] = &#123; -0.5f, -0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 0.0f, 0.0f, 0.5f, -0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 1.0f, 0.0f, 0.5f, 0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 1.0f, 1.0f, 0.5f, 0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 1.0f, 1.0f, -0.5f, 0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 0.0f, 1.0f, -0.5f, -0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 0.0f, 0.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.5f, -0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 1.0f, 1.0f, 0.5f, 0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 1.0f, 1.0f, -0.5f, 0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 0.0f, 1.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, -0.5f, 0.5f, 0.5f, -1.0f, 0.0f, 0.0f, 1.0f, 0.0f, -0.5f, 0.5f, -0.5f, -1.0f, 0.0f, 0.0f, 1.0f, 1.0f, -0.5f, -0.5f, -0.5f, -1.0f, 0.0f, 0.0f, 0.0f, 1.0f, -0.5f, -0.5f, -0.5f, -1.0f, 0.0f, 0.0f, 0.0f, 1.0f, -0.5f, -0.5f, 0.5f, -1.0f, 0.0f, 0.0f, 0.0f, 0.0f, -0.5f, 0.5f, 0.5f, -1.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.5f, 0.5f, -0.5f, 1.0f, 0.0f, 0.0f, 1.0f, 1.0f, 0.5f, -0.5f, -0.5f, 1.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.5f, -0.5f, -0.5f, 1.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.5f, -0.5f, 0.5f, 1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, 0.0f, 1.0f, 0.0f, -0.5f, -0.5f, -0.5f, 0.0f, -1.0f, 0.0f, 0.0f, 1.0f, 0.5f, -0.5f, -0.5f, 0.0f, -1.0f, 0.0f, 1.0f, 1.0f, 0.5f, -0.5f, 0.5f, 0.0f, -1.0f, 0.0f, 1.0f, 0.0f, 0.5f, -0.5f, 0.5f, 0.0f, -1.0f, 0.0f, 1.0f, 0.0f, -0.5f, -0.5f, 0.5f, 0.0f, -1.0f, 0.0f, 0.0f, 0.0f, -0.5f, -0.5f, -0.5f, 0.0f, -1.0f, 0.0f, 0.0f, 1.0f, -0.5f, 0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 0.0f, 1.0f, 0.5f, 0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 1.0f, 1.0f, 0.5f, 0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, -0.5f, 0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f, -0.5f, 0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 0.0f, 1.0f&#125;; 我们还要给每一行再增加6个数据，即 $T$ 和 $B$ 各 3 个坐标。上面一共有 288 个浮点数，让我直接再写 216 个会累死我的，所以切线空间的数据我直接用代码算出来了，实际使用过程中也许在导入模型的时候就可以直接导入切线空间了，当然没有也没关系，因为我已经讲了如何计算切线空间，并且这里也给出了一个例子。下面的代码就是计算切线空间的代码，就如之前说的，很暴力，我并没有多写几个循环来减少几行代码，何必呢。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061float tbnFloats[216]; // 36 个顶点的切线和副切线向量一共有 216 个浮点数// 一个立方体一共有 12 个三角形面(每 2 个构成一个立方体面)for (int i = 0; i &lt; 12; ++i)&#123; Vector3 tbn; int firstIndex = i * 24; // 三角形第 1 个顶点坐标起始索引 int secondIndex = firstIndex + 8; // 三角形第 2 个顶点坐标起始索引 int thirdIndex = secondIndex + 8; // 三角形第 3 个顶点坐标起始索引 // 求得一个三角形的三个顶点坐标 Vector3 pos1(vertices[firstIndex], vertices[firstIndex + 1], vertices[firstIndex + 2]); Vector3 pos2(vertices[secondIndex], vertices[secondIndex + 1], vertices[secondIndex + 2]); Vector3 pos3(vertices[thirdIndex], vertices[thirdIndex + 1], vertices[thirdIndex + 2]); // 求得一个三角形的三个顶点对应的 UV 坐标 Vector2 uv1(vertices[firstIndex + 6], vertices[firstIndex + 7]); Vector2 uv2(vertices[secondIndex + 6], vertices[secondIndex + 7]); Vector2 uv3(vertices[thirdIndex + 6], vertices[thirdIndex + 7]); ／/ 求出三角形的两条边的向量以及 UV 坐标之间的差向量，用于代入公式 // 需要注意的是，当表示 UV 坐标时，x 对应 U，y 对应 V Vector3 edge1 = pos2 - pos1; Vector3 edge2 = pos3 - pos1; Vector2 deltaUV1 = uv2 - uv1; Vector2 deltaUV2 = uv3 - uv1; // 计算切线和副切线向量 // 其实这里就是套用上面求出来的公式 Vector3 tangent; Vector3 bitTangent; GLfloat f = 1.0f / (deltaUV1.x * deltaUV2.y - deltaUV2.x * deltaUV1.y); tangent.x = f * (deltaUV2.y * edge1.x - deltaUV1.y * edge2.x); tangent.y = f * (deltaUV2.y * edge1.y - deltaUV1.y * edge2.y); tangent.z = f * (deltaUV2.y * edge1.z - deltaUV1.y * edge2.z); tangent = glm::normalize(tangent); bitTangent.x = f * (-deltaUV2.x * edge1.x + deltaUV1.x * edge2.x); bitTangent.y = f * (-deltaUV2.x * edge1.y + deltaUV1.x * edge2.y); bitTangent.z = f * (-deltaUV2.x * edge1.z + deltaUV1.x * edge2.z); bitTangent = glm::normalize(bitTangent); // 将每个三角形顶点的切线和副切线数据放到数组里 int startTBNIndex = i * 18; tbnFloats[startTBNIndex + 0] = tangent.x; tbnFloats[startTBNIndex + 1] = tangent.y; tbnFloats[startTBNIndex + 2] = tangent.z; tbnFloats[startTBNIndex + 3] = bitTangent.x; tbnFloats[startTBNIndex + 4] = bitTangent.y; tbnFloats[startTBNIndex + 5] = bitTangent.z; tbnFloats[startTBNIndex + 6] = tangent.x; tbnFloats[startTBNIndex + 7] = tangent.y; tbnFloats[startTBNIndex + 8] = tangent.z; tbnFloats[startTBNIndex + 9] = bitTangent.x; tbnFloats[startTBNIndex + 10] = bitTangent.y; tbnFloats[startTBNIndex + 11] = bitTangent.z; tbnFloats[startTBNIndex + 12] = tangent.x; tbnFloats[startTBNIndex + 13] = tangent.y; tbnFloats[startTBNIndex + 14] = tangent.z; tbnFloats[startTBNIndex + 15] = bitTangent.x; tbnFloats[startTBNIndex + 16] = bitTangent.y; tbnFloats[startTBNIndex + 17] = bitTangent.z;&#125; 接着我们将两个数组合并成一个新的顶点数组： 1234567891011121314151617181920212223float finishVertices[504];// 一共 36 个顶点，按照特定顺序合并即可for (int i = 0; i &lt; 36; ++i)&#123; int finishStartIndex = i * 14; int verticesStartIndex = i * 8; int tbnStartIndex = i * 6; finishVertices[finishStartIndex + 0] = vertices[verticesStartIndex + 0]; finishVertices[finishStartIndex + 1] = vertices[verticesStartIndex + 1]; finishVertices[finishStartIndex + 2] = vertices[verticesStartIndex + 2]; finishVertices[finishStartIndex + 3] = vertices[verticesStartIndex + 3]; finishVertices[finishStartIndex + 4] = vertices[verticesStartIndex + 4]; finishVertices[finishStartIndex + 5] = vertices[verticesStartIndex + 5]; finishVertices[finishStartIndex + 6] = vertices[verticesStartIndex + 6]; finishVertices[finishStartIndex + 7] = vertices[verticesStartIndex + 7]; finishVertices[finishStartIndex + 8] = tbnFloats[tbnStartIndex + 0]; finishVertices[finishStartIndex + 9] = tbnFloats[tbnStartIndex + 1]; finishVertices[finishStartIndex + 10] = tbnFloats[tbnStartIndex + 2]; finishVertices[finishStartIndex + 11] = tbnFloats[tbnStartIndex + 3]; finishVertices[finishStartIndex + 12] = tbnFloats[tbnStartIndex + 4]; finishVertices[finishStartIndex + 13] = tbnFloats[tbnStartIndex + 5];&#125; 这样我们就有一个新的包含 504 个浮点数的数组了，把数组抽象成行列的形式，每个顶点一行，每一行从左到右的形式是这样的：顶点坐标（3个），法线向量（3个），以及纹理坐标（2个），切线向量（3个），副切线向量（3个）。 但其实我这里多了一步，就是当我们求出切线后，只需要让其和三角形表面法线 叉乘 即可，因为他们都是互相垂直的，不过我这里没这么写。 不使用切线空间这个例子使用 OpenGL 编写，我没有全部给出代码，比如如何将这些数据传给 Shader 等，这些对于本篇文章并不重要，也不是本篇文章所要讲的，我在这里会直接给出相关的 Shader 片段，我觉得这就足够了。例子里只有一个立方体，一个平行光，且平行光垂直于立方体朝向世界坐标 Z 轴的一面，而法线贴图采用切线空间下的法线贴图，也就是看起来偏蓝色的法线贴图，这意味着大部分法线值都是偏向正 Z 轴的。 首先我们不使用法线贴图，只使用顶点数组里的顶点法线，来观察一下它的样子，如下图所示： 然后我们加入法线贴图，但不使用切线空间，直接从法线贴图中采样法线向量，再来看下它的样子，如下图所示： 通关观察可以发现，上面两张图中前者是相对正常的，因为整个世界里只有一个垂直于亮面的平行光，所以只能看到一个面有颜色，其它面都是黑色。而后者中，除了垂直于平行光的面，其余面也是有颜色的，这显然是不对的，因为按照物理法则，其余几个面不应该被任何光照到（我也没有添加环境光），所以应该是黑色的。之所以有这样错误的效果，是因为这个立方体六个面都用的相同的漫反射贴图和法线贴图，每一个面不管朝向哪里，采样出来的都是偏向正 Z 轴的值，所以 Shader 代码自然会认为这个面中大部分片段就是面向正 Z 轴的，而我们的平行光正好是照着负 Z 轴，所以这时每个面看起来都有了颜色，这也是我在前面提到的法线贴图的一个问题。 另外，如果你仔细发现，你会看到后者大面积对着屏幕的那一面要比前者大面积对着屏幕的那一面要稍微更有立体感，因为后者我使用了法线贴图，这是法线贴图最基本的作用。但这里的确不明显，因为我为了方便演示，并没有花时间调整出好的光照效果，毕竟这篇文章不是演示法线贴图的，而是用另一个方式去验证切线空间是否计算正确。 使用切线空间为了解决前面的问题，我们需要使用切线空间。切线空间有两种方式可以得到正确的光照结果： 将数据变换到 世界空间 来计算 将数据变换到 切线空间 来计算 很多人喜欢在世界空间中计算，因为将所有数据转换到世界空间再进行计算，是非常直观的，对于我们在讨论的问题也是如此。但这里我们使用第二种方式来计算，原因是它更高效。 如果我们使用第一种方式，我们需要将每个从法线贴图中采样出来的法线变换到世界空间，这一步是在 片段着色器 中完成的，因为必须知道每个片段对应的的法线值，而不能简单的在顶点着色器中采样出来然后再插值到片段着色器中。如果我们使用第二种方式，我们会在 顶点着色器 中把所需要的数据，在这个例子中有平行光方向向量，顶点坐标，观察坐标（因为这个例子只有一个漫反射贴图，所以其实这个数据并没什么卵用）变换到切线空间，然后在片段着色器中只需要采样出法线向量，不需要再进行其他转换就可以直接进行计算了。而一般来说片段着色器执行的次数远大于顶点着色器执行的次数，所以第二种方式一般来说更高效。 当然这里你可能有一个疑问，我们将一些数据从世界空间转换到切线空间，会涉及到矩阵的求逆，这一步是开销比较大的。理论上说，是的，但实际上，我们利用一个性质，即 正交矩阵的逆矩阵等于它的转置矩阵 就可以做到高效求逆矩阵，你在后面会看到。 顶点 Shader首先我们将顶点数组传入顶点着色器，然后构造 TBN 矩阵 来把一些数据变换到切线空间，最后再传入到片段着色器里。我先列出顶点着色器中所需要的数据(除传入的顶点数据外，其余数据都是在世界空间下)： 123456789101112131415161718192021222324#version 330 corelayout (location = 0) in vec3 vertexPosition; // 顶点坐标layout (location = 1) in vec3 vertexNormal; // 顶点法线layout (location = 2) in vec2 textureCoordinate; // 顶点纹理采样坐标layout (location = 3) in vec3 tangent; // 顶点切线layout (location = 4) in vec3 bitTangent; // 顶点副切线// 这是 OpenGL 中的 uniform 缓存，就是把一次渲染中不变的通用数据从外部代码传给 Shaderlayout (std140) uniform CameraInfo&#123; vec3 viewPosition; // 摄像机位置（观察位置）&#125;;// 平行光的数据struct DirectionalLight&#123; vec3 direction; // 方向 vec3 diffuseColor; // 漫反射颜色&#125;;uniform mat4 mvpMatrix;uniform mat4 modelMatrix;uniform DirectionalLight directionalLight; 然后我们还需要定义输出给片段着色器的数据： 12345678out V_OUT&#123; vec2 textureCoordinate; // 纹理坐标 vec3 vertexPosition; // 切线空间顶点坐标 vec3 normal; // 发现向量 vec3 viewPosition; // 切线空间观察坐标 vec3 directionalLightDirection; // 切线空间平行光方向&#125; v_out; 这些数据定义好后，我们就可以着手编写转换各个数据到切线空间的代码了： 1234567891011121314151617181920212223242526void main()&#123; // 计算顶点的世界坐标 vec4 vertexPositionVector = vec4(vertexPosition, 1.f); gl_Position = mvpMatrix * vertexPositionVector; // 计算法线矩阵(这个矩阵可以使法线的坐标空间变换更精确，详细信息可以查阅【法线矩阵】 或 【Normal Transform】) mat3 normalMatrix = transpose(inverse(mat3(modelMatrix))); // 求 TBN 矩阵，三个向量均变换到世界空间 vec3 T = normalize(normalMatrix * tangent); vec3 B = normalize(normalMatrix * bitTangent); vec3 N = normalize(normalMatrix * vertexNormal); // 求 TBN 矩阵的逆矩阵，因为 TBN 矩阵由三个互相垂直的单位向量组成，所以它是一个正交矩阵 // 正如前面所说，正交矩阵的逆矩阵等于它的转置，所以无需真的求逆矩阵 // 详情可查阅 【正交矩阵】 或 【Orthogonal Matrix】 mat3 inverseTBN = transpose(mat3(T, B, N)); // 将一些数据从世界空间变换到切线空间（并非所有数据都需要变换），然后传给片段着色器 v_out.directionalLightDirection = inverseTBN * directionalLight.direction; v_out.vertexPosition = inverseTBN * vec3(gl_Position); v_out.viewPosition = inverseTBN * viewPosition; v_out.textureCoordinate = textureCoordinate; v_out.normal = N;&#125; 写到这里我发现，我本来想只放出 Shader 片段的，但最后还是把整个顶点着色器的代码都写上了。我在里面添加了详细的注释，应该不会有什么很困惑的地方。 片段 Shader由于我们将数据都变换到了切线空间下，那么片段着色器在计算的时候就方便多了，因为它们都在同一个空间下了。同样我们先定义所需要的数据： 1234567891011121314151617181920212223242526272829#version 330 coreout vec4 f_color; // 输出的颜色// 这个跟顶点着色器中的 out 一致in V_OUT&#123; vec2 textureCoordinate; vec3 vertexPosition; vec3 normal; vec3 viewPosition; vec3 directionalLightDirection;&#125; v_out;struct Material&#123; sampler2D diffuseTexture; // 漫反射贴图 sampler2D normalTexture; // 法线贴图&#125;;// 跟顶点着色器中的一致struct DirectionalLight&#123; vec3 direction; vec3 diffuseColor;&#125;;uniform Material material; // 材质uniform DirectionalLight directionalLight; // 平行光信息 最后计算最终的颜色： 12345678910111213141516171819202122vec3 viewDirection; // 观察方向vec3 CaculateDiractionalLightColor()&#123; // 从法线贴图中采样出数据，并转换成法线值 // 转过算法为：贴图中存储 0 到 1 的值，而法线值是 -1 到 1 vec3 normal = vec3(texture(material.normalTexture, v_out.textureCoordinate)); normal = normalize(normal * 2.0 - 1.0); // 计算漫反射 float diffuseRatio = max(dot(-v_out.directionalLightDirection, normal), 0.0); vec3 diffuseColor = directionalLight.diffuseColor * diffuseRatio * vec3(texture(material.diffuseTexture0, v_out.textureCoordinate)); // 因为这个例子只用了漫反射贴图和法线贴图，所以其余如镜面反射或者环境光等就不计算了 return diffuseColor;&#125;void main()&#123; viewDirection = normalize(v_out.vertexPosition - v_out.viewPosition); f_color = vec4(CaculateDiractionalLightColor(), 1.0); // 输出最终颜色&#125; 例子的结果最终的结果如下图所示： 从图中可以看到，除了正对着平行光的一面外，其余面在凹凸的地方会有一点颜色，而其他地方依然是黑色。这是因为对于这个砖墙的图来说，在法线贴图中砖的凹凸处所对应的法线向量显然不是 $(0, 0, 1)$ ，所以在这个使用了切线空间的例子中，平行于平行光方向的面转换到切线空间后，可以直接对法线贴图进行采样，而砖墙的大部分面积采样出来的法线向量是 $(0, 0, 1)$ ，所以对于平行于平行光方向的墙面来说，大部分像素的法线向量都垂直于平行光照射的方向，所以计算出的颜色自然为0，而砖墙的凹凸处的法线值不垂直于平行光照射的方向，所以会得到一些颜色，这应该足以说明我们的切线空间计算结果是正确的。]]></content>
      <categories>
        <category>图形</category>
      </categories>
      <tags>
        <tag>图形 数学 切线空间 法线贴图 视差贴图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[判断单向链表是否有环及求环入口的算法数学证明]]></title>
    <url>%2F2017%2F10%2F09%2F%E5%88%A4%E6%96%AD%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8%E6%98%AF%E5%90%A6%E6%9C%89%E7%8E%AF%E5%8F%8A%E6%B1%82%E7%8E%AF%E5%85%A5%E5%8F%A3%E7%9A%84%E7%AE%97%E6%B3%95%E6%95%B0%E5%AD%A6%E8%AF%81%E6%98%8E%2F</url>
    <content type="text"><![CDATA[读者您好：本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！ 概要本篇文章，主要讲解 title 中所描述算法的原理及数学证明。需要注意的是，本篇中出现的代码未必是完整代码，可能只是一个关键代码块，且采用 C++ 编写。 判断链表是否有环当单向链表中存在环的时候，遍历此链表会发生无限循环，无法到达末尾（实际上并没有末尾）的情况，所以在可能发生这种情况的时候，需要检查链表中是否存在一个环。 算法算法很简单，设置两个指针，分别为快指针（fast）和慢指针（slow），快指针每次向前走两步，慢指针每次走一步。如果快指针指向了 NULL，那么说明此链表中没有坏，因为有环会发生无限循环，不可能走到末尾。而在有环的情况下，两个指针会在环里绕圈，最终指向同一个地址，即两个指针相遇，根据这个就可以终止遍历代码且证实链表有环。 附上关键代码： 12345678910ListNode *slow = head-&gt;next;ListNode *fast = slow-&gt;next;while (fast &amp;&amp; slow != fast)&#123; slow = slow-&gt;next; fast = fast-&gt;next ? fast-&gt;next-&gt;next : NULL;&#125;return fast ? true : false; 有环时两个指针一定会相遇的数学证明在做这道题的时候可能会有疑惑：为什么在有环的时候两个指针一定会相遇？这里给出数学证明。 当 slow 指针一步步走到环的入口时（注意此时 fast 已经在环里了，因为它比 slow 要快），设： 链表头指针 head 到链表环的入口处的距离为 $ L_1 $ fast 指针距离环的入口的距离为 $ L_2 $ fast 已经在环内走了 $ N_1 $ 圈（向下取整） 假设 slow 再经过 $ i $ 步与 fast 相遇 环的周长为 $ C $ fast 和 slow 走过的总路程分别为 $ disFast $ 和 $ disSlow $ 示意图如下： 则当 slow 走到环入口时，可得知： disFast = L_1 + L_2 + N_1C disSlow = L_1又因为 fast 每次走两步，即比 slow 快一倍，所以 若两个指针相遇，则有： (disSlow + i - L_1) \; mod \; C = (disFast + 2i - L_1) \; mod \; C减去 $ L_1 $ 是为了减掉不在环内的长度从而求得相遇点相对于环入口的距离，由于等式两边的值实际上是相对于环入口的距离，所以有： i \; mod \; C = (L_2 + N_1C + 2i) \; mod \; C \Rightarrow (L_2 + N_1C + i) \; mod \; C = 0 \Rightarrow (L_2 + i) \; mod \; C = 0 \; (加减 C 的整数倍对于取模来说没有影响）可以看到， $L_2$ 和 $i$ 总和等于环的周长的整数倍，这个等式是成立的，实际上我们也求出了 $i$ 的值。结合图和最终的等式，我们可以看到，对于任意 $L_2$ ，都可以求出无数个 $i$ 值，每个值都对应一个周长的整数倍，而对于每一个 $i$ 值，最终相遇的位置都一样，这也很好理解，当 $slow$ 和 $fast$ 相遇后，由于 2 倍速度的关系，当 $slow$ 继续走半圈的时候，$fast$ 走了一圈回到了之前的相遇点，当 $slow$ 再走半圈回到之前的相遇点， $fast$ 又走了一圈再次回到之前的相遇点。 这就是对于在有环的单链表中快慢指针一定会相遇的数学证明。 求环的入口在上一个问题之后，还有一个相关的问题，即如果此链表有环，求环的入口节点。直接想此算法可能比较难解，所以这个问题可以尝试着从数学上入手。 数学设 (注意与上一个问题所表示的含义可能有不同) ： $ L_1 $ 为链表头 head 到环入口的距离 $ L_2 $ 为从环入口向前到相遇点的距离 $ L_3 $ 为从相遇点向前到环入口的距离 (按照指针前进的方向计算) $ C $ 为环的周长 $ N_1 $ 和 $ N_2 $ 分别为 slow 和 fast 在相遇时走过的圈数（向下取整） $ disSlow $ 和 $ disFast $ 分别为 slow 和 fast 在相遇时走过的距离 示意图如下： 则： disSlow = L_1 + L_2 + N_1C disFast = L_1 + L_2 + N_2C又因为 fast 速度是 slow 的 $ 2 $ 倍，所以： disSlow * 2 = disFast \Rightarrow 2(L_1 + L_2 + N_1C) = L_1 + L_2 + N_2C \Rightarrow L_1 + L_2 + 2N_1C = N_2C \Rightarrow L_1 = (N_2 - 2N_1)C - L_2因为 $fast$ 的速度是 $slow$ 的两倍，所以 $N_2$ 至少是 $N_1$ 的两倍（至少而不是恰好是因为 $fast$ 进入环时 $slow$ 可能还没进入环，所以 $fast$ 可能会先在环内走几圈）， 即 N_2 >= 2N_1这里其实还可以求出的是，当 $N_2$ 等于 2 倍的 $N_1$ 的时候，$L_1$ 和 $L_2$ 都为 0 ，也就是整个链表就是一个环 。 由此可以看出，$ L_1 $ 即链表头 head 到环入口的距离就等于 $(N_2 - 2N_1)C - L_2$，其实就等于 $L_3 + (N_2 - 2N_1 - 1)C$ （注意 $L_3$ 是按照指针前进方向算的，并不是最小距离，所以这个结果对于整个链表都是环也是有效的） ，而从相遇点向前走 $L_3 + (N_2 - 2N_1 - 1)C$ 的距离，正好就走到了环的入口（如果没理解可以在图上比划一下即可），所以我们就可以推导出算法，即：让两个指针其中一个从链表头 head 出发，一次走一步，让另一个指针从相遇点出发，也一次走一步，相遇点就是环的入口。 算法关键代码如下： 1234567slow = head;while (slow != fast)&#123; slow = slow-&gt;next; fast = fast-&gt;next;&#125; 注意事项这里有一个小坑，在算法的最最开始，可以让 slow 和 fast 都为 head 指针，或者 slow 为 head 的下一个节点，fast 为下两个节点。如果让 slow 为 head 指针，fast 为下一个节点，则可能无法求出环的入口，甚至可能陷入死循环。但对于第一个问题，这个步骤没有影响。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法 链表 数学</tag>
      </tags>
  </entry>
</search>
