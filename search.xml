<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[对 Gamma 校正的个人理解]]></title>
    <url>%2F2018%2F02%2F24%2F%E5%AF%B9-Gamma-%E6%A0%A1%E6%AD%A3%E7%9A%84%E4%B8%AA%E4%BA%BA%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！如果在第三方阅读发现公式等格式有问题，请到原文地址阅读。 为什么要写这篇文章Gamma 校正，看起来似乎是一件很简单的事情，做一次幂运算就可以了，但是如果深究的话，就会发现 Gamma 校正是个有点容易让人混乱的东西，每个人的解释可能都有一些不一样。在解释 Gamma 校正的时候，经常会拿出几张容易令人混淆的表示亮度值的图，再就是需要频繁在不同颜色空间中转换，绕来绕去，最主要的是，Gamma 值在不止一个地方会用到，而这些地方应用的时候还或多或少有一些关联，且这几个地方的用到的值还都很接近，所以深究 Gamma 校正的时候，非让容易令人感到困惑。我在读了不少资料，自己进行了一番理解之后，打算写一篇文章记录和分享一下自己的所得。当然，我也只能说我会把自己的理解尽可能清楚地表达出来，如果有错误，欢迎批评指正。 Gamma 是什么物理亮度物理亮度，可以认为是由光子数量来决定的，并且亮度与光子数量成线性关系，也就是说物理亮度存在于一个线性的空间中，物理亮度每提升 0.1，亮度的增加都是相同的。先说明这一点也是为了避免读者在后面的文字中对提到的物理亮度与其他东西感到混淆。 Gamma 的由来Gamma 的由来，说法是不统一的。 大部分人认为是由于早期 CRT 显示器的问题，即输出的亮度和输入的电压并非线性关系，而是近似 2.2 次幂的关系，导致进入人眼的亮度要比计算机上存储的亮度要低。例如，计算机上存储的亮度为 0.5，经过显示器调整后变为 0.5 的 2.2 次幂，即 0.218。为了让进入人眼的亮度与计算机中存储的值相同，需要在显示器调整前将亮度变为自身的 1/2.2 次幂，即 0.73，这样在经过显示器的调整，进入人眼就是 0.5 了，也就是说，Gamma 校正可以补偿由于显示器造成的亮度下降。这里需要注意的是，2.2 这个值是一个近似值，或者可以说是一个标准，实际上可能会有不同，现在的显示器甚至可以调节。 而我在查阅资料时，发现还有一种说法是，人眼对不同亮度的敏感程度是不同的，例如对暗部的敏感要高于亮部，而对物理亮度（真实物理世界的光子数量）的最终感知值近似于物理亮度的 1/2.2 次幂，即和上面提到的 CRT 显示器的 Gamma 值互为倒数，可以说是一个巧合，如下图所示： 第一行的数字表示在计算机中存储的亮度值，也就是说经过显示器和人眼的两次调节后，最终感知到的亮度就是上面的数字。我们可以看到，数字越低，变化越明显，即人眼对暗部更敏感。 第二行的数字并不是直接存储在计算机中的，在计算机中存储的是经过 Gamma 校正后的值，即图中数字的 1/2.2 次幂，那么经过显示器一次调节后，得到的结果就是图中的数字，也就是说人眼看到的就是物理世界的亮度。由于人眼还会调节，所以你看到的依然不是线性变化的，但依然可以看出人眼对暗部更敏感。 我们并不需要太关心哪种说法是真正的起源，其实这两种说法都是正确的，我们只需要明白 Gamma 是什么即可，我们可以通过一张图来直观的解释： 横坐标为输入值，纵坐标为输出值，中间的点线是物理亮度值，下方的实线是经过显示器校正的曲线，而上方的虚线是我们进行 Gamma 校正后的曲线，也近似于人眼调解后的曲线。 这一节只是简单介绍一下 Gamma 是什么，如果觉得不明白，后面都会进行更详细的解释，而在图形学的应用中，我们更关心的是跟显示器有关的部分，但第二种说法在图形学中也有一定的应用。 现代显示器还需要 Gamma 校正吗前面提到，CRT 显示器会有这个问题，那么现代显示器呢？其实现代显示器就算没有 CRT 这个问题，也会保留这个特性。至于为什么，有人说是因为正好迎合了前面提到的人眼的特性，亮暗变化正好相抵，但我个人认为这是不对的。 假设有一个物体，物理亮度是 0.5，人眼感知会变成 0.73，而如果在计算机中存储的亮度就是 0.5，经过显示器调节后变为 0.218，人眼再感知就会又变成 0.5，这与真实世界不符，我想不出有什么理由要这么做。 而现代显示器还需要 Gamma 的原因，我觉得更可能是因为一方面要兼容老的 CRT 显示器，另一方面是因为诸如相机等设备保存的图片很多其实都是经过 Gamma 校正过的，这个后面会讲到。 关于这个问题，我在网络上搜了一下，也没有看到什么很明确的回答，如果读者知道，欢迎留言，这里我们最主要是要了解现代显示器依然有 Gamma 值存在即可。 Gamma 校正的几个颜色空间线性空间Gamma 校正除了可以补偿亮度的损失之外，它在图形学中一个非常重要的作用是，它使得我们在计算光照的时候使用的数据是正确的。请看上面的曲线图，中间的直线就是线性空间的值。 假设计算机中存储的亮度值代表的就是我们想模拟的物理世界的值，即存储在线性空间中。当存储的亮度为0.5，我现在想要模拟在物理世界里把亮度值提到 2 倍，通常来说我应该直接将 0.5 乘 2，这样看起来没什么问题，但通过曲线图可以得知，计算机中存储的亮度值为 0.5 时，经过显示器进入物理世界的亮度为 0.218 ，而存储的亮度值为 1 时，经过显示器进入物理世界的亮度值依然为 1，也就是说亮度值在物理世界里提高了 4 倍多！这显然与我们想要的不符。使用 Gamma 校正就可以解决这个问题，首先将最初的 0.5 进行幂运算变到 0.73，这样经过显示器输出后，就是 0.5, 而将 0.5 变为两倍后，再进行 Gamma 校正和显示器的调整，输出的值仍然是1，就符合了两倍的规则。 几乎所有的计算，都要在线性空间下进行，因为这更符合物理规律，所以如果计算机中存储的颜色值是在线性空间下的，那么如果对其进行计算后没有进行 Gamma 校正，得到的结果就不是我们预期的（注意我并没有说这样的效果一定不好，只能说不是我们预期的）。 需要注意的是，如果存储的值本身就不在线性空间下，则在进行计算时，需要把它转换到线性空间下计算，然后再转换回原来的空间中，以进行后续的操作。否则，你的算法是作用在线性空间下的，但你操作的值不是线性空间的值，就会有问题。 sRGB 空间sRGB（standard RGB）是微软和惠普一起定制的颜色格式，在 sRGB 格式下，Gamma 值为 2.2。具体的 sRGB 和 线性空间转换的公式为： sRGB(x) = \begin{cases} 12.92 x, & x 0.0031308 \end{cases}\\[2ex] x \; 为\text{线性空间中的颜色}\\[4ex] linear(x) = \begin{cases} \frac {x} {12.9}, & x 0.04045 \end{cases}\\[2ex] x \; 为\text{sRGB空间中的颜色}但一般我们自己计算的时候，都会直接用简化形式，即变为 2.2 次幂 或者 1/2.2 次幂。 sRGB 对应曲线图中的上方虚线，我们之前的一些操作，就是把颜色值从线性空间变换到 sRGB 空间，这样经过显示器调节后又变到线性空间了。 sRGB 空间有一个很重要的作用，就是我们用来存储颜色的媒介往往不够存储很多细节，比如常用的 RGBA32，每一个通道只有 8 位，即 0 到 255，只能存 256 个级别的亮度，这会丢失很多物理世界里的真实信息。那么如何在不增加存储范围的情况下，尽可能保留更多的物理信息呢？答案是，通过 Gamma 校正，把较暗的部分的存储范围放大，当然这会导致较亮的部分丢掉一些细节。这么做的依据是前面提到的人眼对暗部更敏感，所以应该用更多的范围去存储较暗的部分，而亮的部分，即使丢失掉一些细节也没关系，因为人眼可能并不会感知到。 举个例子，我们采样到的亮度为 0.218，如果就这么直接存储，那么我们采样的所有 0.218 以下的亮度都只能保存在 0.218 这个值以下，换成 8 位二进制表示只有 256 乘 0.218 等于 55 个级别。而 0.782 到 1 的值直接保存的话，也是 55 个级别，这样就造成了浪费，因为我们对 0 到 0.218 这个范围的敏感程度要大于 0.782 到 1 这个范围，而这两个范围都用 55 个亮度级别去表示，这就会使得我们本来可以感觉的更多的暗部的细节，但现在感觉不到了。 当我们用 Gamma 校正去做这件事情，情况就会不一样。0 到 0.218 这个范围经过 Gamma 校正后，会变为 0 到 0.5，也就是说我们可以用 128 个级别去存储 0 到 0.218 这个范围，这样我们可以感受到 128 个级别的亮度，而 0.782 到 1 经过 Gamma 校正后的范围是 0.9 到 1，也就是只有 26 个级别。这符合我们人眼的特性，前面提到过，人眼感知物理亮度的曲线，也大约符合 Gamma 校正后的曲线。 现代的摄像机等设备，都可以把照片用 sRGB 空间存储，我们在进行计算的时候，如果是 sRGB 空间的，需要先将其转换到线性空间，然后再进行计算。注意计算和存储是不一样的，8 位每通道的存储在计算的时候的精度可以不止 8 位。这也是我前面说现在的显示器仍然保留 Gamma 这一特性的原因，因为这样经过屏幕的调整后进入物理世界的就是摄像机所拍物体的真实颜色。 颜色空间对游戏开发的影响设计师在制作纹理的时候，最方便的方法自然是自己看到什么就是什么。比如设计师绘制了一张颜色为 (0.5, 0.5, 0,5) 并且觉得这个颜色刚刚好，然后他保存了这张纹理交给程序员。那么这张纹理存储的颜色是在哪个颜色空间呢？答案是 sRGB 空间。因为这张图经过屏幕进入物理世界后的值是 0.218，也就是说进入设计师眼睛的颜色是 0.218，然后眼睛再进行调节。而现在我的光照算法会把亮度提升 2 倍（注意这个 2 倍是物理世界线性空间下的，即 0.436，而不是人眼感知的 2 倍，人眼调节后就不是 2 倍了），显然不能把纹理中存储的 0.5 直接乘 2，因为那样实际上物理亮度提升了 4 倍多，就如我们最开始那个例子一样。所以这个纹理存储的是 sRGB 空间的值，即曲线图上方的虚线，我们进行计算时需要先转换到线性空间，计算完成后再转回到 sRGB 空间，这样就是设计师最初想要人看到的颜色了。 而如果因为一些原因，设计师直接出了一张线性空间的图，那么在计算时不需要进行转换，但是输出的时候，需要进行一次 Gamma 校正，转换到 sRGB 空间，这样输出到物理世界的值就是计算机纹理中存储的线性空间的值了。 关于纹理颜色空间的选择那什么时候需要线性空间呢，什么时候需要 sRGB 空间呢？ 我个人认为的是，表示颜色的纹理应该选择在 sRGB 空间，因为这可以改变不同明暗的颜色的存储范围，使其更符合人眼特性。而一些表示纯数值的纹理，就直接选择线性空间即可，不需要再换转了，因为他们本身就是用于计算的。比如一张表示 Phong 光照模型中物体镜面反射程度的镜面反射贴图，就直接选择线性空间的值即可，采样后就直接可以参与计算了。 一个可能的错误想法是，假设表示光源颜色的纹理存储的颜色是 x (这里为了方便就直接用一个 x 代替了)，镜面反射程度是 y，那么镜面反射的颜色通过屏幕后进入物理世界的的值为 $(xy) ^ {2.2}$，这其实是不对的。因为如果颜色值是 sRGB 空间的，那么正确结果是 $((x ^ {2.2} y) ^ {1 / 2.2}) ^ {2.2} = (x ^ {2.2} y)$, 观察这个结果会发现，就是 sRGB 空间的颜色转换到线性空间，然后再进行计算。如果颜色值是线性空间的，那么正确的结果是 $((xy) ^ {1 / 2.2}) ^ {2.2} = xy$，即用两个线性空间的值直接进行计算。 总结这篇文章的目的主要是梳理 Gamma 校正到底是什么，实际使用时，Gamma 校正还有一些地方需要注意，尤其是在使用纹理的时候，有机会我也会进行一些探讨。 以上关于 Gamma 校正相关的解释都是我个人的理解，如果有不对的地方，还请指出。 感谢阅读。 参考资料 Learn OpenGL — Gamma Correction wikipedia — Gamma correction wikipedia — sRGB Gamma校正与线性空间 What is the purpose of gamma correction in today’s screens and how does it relate to graphics and photography? 知乎 — 色彩校正中的 gamma 值是什么？]]></content>
      <categories>
        <category>图形</category>
      </categories>
      <tags>
        <tag>Gamma Gamma校正 图形 游戏开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Global Game Jam 2018 经历分享]]></title>
    <url>%2F2018%2F01%2F29%2FGlobal_Game_Jam%20%E7%BB%8F%E5%8E%86%E5%88%86%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！ 关于本文很久以前就听说过 Global Game Jam（以下简称 GGJ），但因为一些原因没有参加过，很高兴这次终于能来参加这样有趣的活动。在这里先附上我们这次做的游戏的几个相关链接，有兴趣的朋友可看看。 我们的 b 站视频通关链接，up 主是我们的队长。 b 站视频通关 还有我们的 GGJ 2018 的页面。 中文站原站 别怕，文章不是很长，后面图不少。 关于 Global Game JamGGJ 是一个大型的线下独立游戏节，全球各地都有站点，今年我没记错的话有 100 多个。全世界的独立游戏开发者在此时一起参与，围绕同一个主题，组队或者单人在 48 小时内按照自己的想法去开发游戏。对于游戏本身几乎没有任何限制，主题也很开放，所有人都可以充分发挥自己的想象力，去制作一个自己喜欢的游戏。 值得注意的是，这个全球一起参与是有时差的，比如 15 点开始，那么每个站点就都是当地 15点开始，所以一些站点就会更早得到主题，而开发者们需要在最后一个站点公布主题之前对主题进行保密。 第一天主题公布大概三点半左右，我和同事们一起到了北京站会场进行签到，这也是我们这次的队伍的大部分成员。 之后就在会场内坐着观看暖场视频并与其他人进行交流。据我观察，大部分可能都是学生，这也比较符合常理，学生更有热情和时间。过了没多久，本次活动终于正式开始了，主持人也就是 CIGA 的创始人在进行了一段讲话后，就开始播放主题视频。 本次的主题和去年的主题有很大相似的地方，去年是 Waves ，今年是 Transmission ，他们都有传输方面的意思，而今年的主题，除了传输这类意思，还可以理解成传动，当然这种开放式的主题怎么理解都有道理。 主题公布以后，北京站还有一个额外的活动，请了乐元素的一个制作人来进行一场有关商业游戏和独立游戏的分享，这之后才是组队环节。 组队报名 + 赶去参加公司的年会然而我们公司的年会和这次活动的时间重合了，有一些事情得在年会上去做，所以当组队报名开始后，我和同事们立即登记好了信息，便赶去了年会地点。 由于提前就组好了队，所以我们可以直接进行队伍报名，我们的组号是 02，很靠前，由于我们想做一个像素游戏，我们的队名就叫做 Bit Bit 。赶往年会途中被同事告知我居然中了奖23333333。（请注意这是描述性词语，不是我中了 23333333 数额的奖金） 8点左右到了年会，必不可少的与各个领导和同事轮番敬酒／可乐／雪碧／芬达／水／空气，回到会场时已经11点多了。 由于我们的美术小伙伴暂时还并不是我们的同事，所以没有办法只能让他一个人先在会场里与其他人进行交流和等我们回来了（这里给美术大大点赞！后面试玩很多人都赞扬我们的美术）。 由于已经喝了一些酒，虽然还算清醒，但是感觉已经不适合去会场了，所以我们打算在提前订好的酒店里商量做什么，然后大家就去睡觉，第二天正式开工（喝完酒写代码还不一堆 bug）。 决定游戏开发计划这大概是整个过程中最重要的一环了，毕竟游戏的设计直接决定了游戏的质量。 游戏方向首先我们进行且仅进行了一轮头脑风暴式的交流，每个人说出自己从主题公布到现在的想法，但最后大部分想法都被直接否决了，不是这些想法不好，而是这种活动，创意很重要，对于 Transmission 这个主题，我们直观上想到的传送带，传输光，连接物体进行传输这些具体的概念应该都是很容易被别人想到的，所以可能会让人觉得创意不足，而那些抽象的概念，可能就不会有那么多人想到，就更会让人觉得新奇。在我们之前的讨论里，我们队伍里的策划小伙伴有一个关于 纸飞机 的想法，纸飞机是一个具体的东西，但是纸飞机本身就经常被用来作为抽象概念的载体，比如爱情，思念等，加上 Transmission 这个主题，可以做一个用纸飞机传达情感的游戏，即表面上用物理概念下的纸飞机飞来切合主题，然后深层次上用传递情感来升华这个主题。 除此之外，我们还保留了两个想法，讨论的时候是这三个想法一起讨论的，因为要考虑时间和难度的问题。有一个想法在技术上很容易实现，所以被我们否决了，毕竟我们也是专业团队，感觉如果做的特别简单，可能自己心里也过不去。另一个想法在一些设计问题上我们暂时没有想到特别好的思路，所以也否决了。 最终我们决定做纸飞机相关的想法，然后为了避免意外，我们把那个简单的游戏作为候补，如果前一个游戏出现重大问题，我们也能在短时间内坐制作一个可以给别人玩的小游戏。 内容细节游戏方向决定后，我们开始讨论游戏的细节（为了文章的流畅度，这里要说明一下，有一些细节是在第二天我们正式开始做的时候决定添加的）。纸飞机也是飞机，自然是要飞的（废话），这也是表层的 Transmission ，体现在玩法上就是飞机要从起点飞到终点，到达终点就可以进入下一关。这种玩法自然飞行过程中要有障碍物，所以我们在场景中摆放了很多建筑，这些建筑都带有 死亡碰撞体 ，纸飞机碰到游戏就会失败。而纸飞机是没有动力的，我们需要给它添加一个力，让他可以飞到终点，这个我们决定使用物理系统来对纸飞机进行推动，体现在玩法上就是吹风机对纸飞机的吹动。整体上来说，玩家需要摆放吹风机，从而影响飞机的飞行路线，最后让飞机抵达终点。这就是整个游戏的核心玩法。 决定了表层后，就轮到深层了。纸飞机可以用来传达情感，这也是深层的 Transmission 。传达的过程中可能会遇到挫折，就好比人在传达爱意的时候，可能会遇到各种失败，而经过不断的努力尝试，才能传达到爱慕之人的心里。所以不仅我们的关卡也被设计成越来越难，在表现形式上也增加了狂风和雷雨的天气（时间原因只做了四个关卡，但是策划小伙伴搭的场景很棒），越到后面天气越恶劣，在这些关卡里绝大部分玩家需要反复不断的尝试，才可能成功，我们希望能让玩家体验到，情感的传达可能很困难，需要不断努力。 艺术风格来之前，我们已经确定了我们采用像素风格来作为游戏的艺术风格，而在此基础上，我们需要决定游戏的背景设定，是现代，还是古代，是充满科技感的未来，还是荒凉凄冷的末世。我们的美术大大很给力，我们所提出的风格想法他都能 hold 住，当然在这方面我们只能提供意见，如果美术大大不同意，那这个风格就会被否决。 末世这个题材，和情感这个略微暖一些的题材放在一起，莫名有一种反差之美，最终我们也决定了末世的背景设定，即末世加像素的艺术风格。 明确分工当天晚上的最后，我们开始决定分工。其实我们也并没有很明确的进行分工，就是简单交流了一下技术方案，设计方案，明确了下每个人大概的工作内容。在实际制作过程中，大家都会或多或少的做一些别的工作，例如 订外卖，取外卖，解决多出来的吮指原味鸡，寻找凌晨两点在黑暗的大楼里不小走失的同伴 等等。 睡觉时光飞逝，岁月如梭，终于到了睡觉的时间。洗漱完毕后，劳累了一天，我们很快就进入了梦乡（然而我并没有做梦）。 第二天第二天，我们早上来到会场，发现前一天占领的桌子已经被来得更早甚至没走的人占领了（所以大家尽量早点去），于是我们在会场里又拼凑了几张桌子，开始了正式的开发。 由于很多东西都提前定好了，还有很多学生队伍不知道或不会使用版本控制，所以我们开发的速度还算是相对比较快的，主要是已经有几年的游戏开发工作经验了（我个人算上实习是两年半多一些，队里其他人大部分都比我多），在很多问题上能比较快的解决。 独立游戏大神确实是有的，从外形上再到作品上都能体现出来，也有本身就在网上有知名度的大神来参加，很多人从发型上就能看出来是搞艺术设计的，当然也有很多也能看出来是学生。 这一天我们基本完成了整个游戏流程和核心玩法，还剩一些 bug 和 细节打算在最后一天去解决。这一天虽然中间有闲逛的时间，但是整体还是很紧凑的，我开玩笑说这个游戏要是在公司里可能需要排两个礼拜的工期，果然 Deadline 是第一生产力。其实这一天倒没那么多可说的，因为一天基本都在开发，一直从上午10点开发到半夜快3点，虽然很累，但是内心其实是很快乐的。 第三天最后的冲刺终于到了最后一天，这一天下午我们要完成产品，准备试玩，并上台演示。游戏还剩一些 bug 没解决，细节还有一些没做完，这些都要在下午 3 点前搞定。虽然游戏在昨天已经能玩了，但是我们还是希望能把游戏的完成度提高。 我们要做的大概有：设计好关卡的难度和特效等细节，做好返回和继续的流程，提高一些游戏内用户体验的东西，增加通关后 all clear 场景并用动画展示开发人员名单，制作完 all clear 场景的通关画面和动画，增加场景切换动画，找到并添加多个 bgm，重写背景移动的功能（周六早上我花了10分钟用 shader 移动 uv 来完成这个功能，然而发现这个做法并不适应我们之后的需求，在花了很长的时间兼容需求但无法完美解决之后，最终还是在周日早上又花了 10 分钟用另一种方法完美实现了），修复所有已知的bug，增加若干场景内物件的动画，还有一些东西暂时想不去来了。这些东西要在上午 10 点多到下午 3 点前做完，开发时间还是有点紧张，不过最后还是都顺利完成了，这得益于大家的专业技能和都想把游戏做好的心。 现场试玩开发截止后，是短暂的试玩环节，我们的游戏相对来说有较高的完成度（反正玩家是这么说的）并且艺术风格看起来也很不错，吸引了很多人来玩，也有官方的美女来用手机在直播平台进行直播（频繁上镜），并且把整个游戏从开始到结束加上队长的实时讲解都完整的播了出来（不知道能不能找到录播），最后还配合 all clear 场景的开发人员介绍动画把小伙伴们都介绍了一遍。 从大家的反馈来看，一个是完成度相对较高（毕竟只有48小时，我们这个也算挺高的了），另一个是艺术风格很令人喜欢，尤其是对于女性玩家来说。 我也去试玩了一些其他队伍的游戏，大家的想法都挺有意思的，跟他们交流，能收获不少新思路。 展示短暂的试玩结束后，到了最后的展示的环节。我们是第 2 组，所以观众都在。第一组做的一个模拟氪金抽卡的游戏，有点恶搞的意思，但是展示效果很欢乐，本来想去玩玩，但是后来找不到了，之后就是我们组了。 展示我们的游戏 我们队的队长一边玩一边讲述这个游戏的开发思路，为什么要做这个，每一关为何这么设计，我们要表达的是什么。展示前也一一介绍了团队的成员。游玩过程中配合 bgm 和像素末世场景，加上队长的讲解，相信是能给观众带来一定的思考的。 通关展示完毕，通关成功！（下图少了一个小伙伴的证书） 观看别人的游戏和与别人交流展示完成后，我们就在观看别人的展示，以及和其他人交流并且继续提供试玩。展示环节有很多非开发者来观看，貌似大多都是发行方面的人。喜欢我们游戏的人还是不少的，也有很多人和我们交流他们对我们游戏的想法，给我们提供了一些建议。看到别人喜欢自己的游戏，大概是对于一个游戏开发者最好的褒奖吧。 出乎我意料的是，有不少队伍都选择了单机多人对战游戏，我本以为在这样的活动中，选择纯单机是一个更好的选择，但是这些独立游戏开发者着实给我上了一课。 感受第一次参加这种活动，感受很多。我不仅见识了国内其他游戏开发者的热情，也看到了很多人很棒的点子，并且为之努力的认真劲。自己从小时候起就梦想长大后能成为一名游戏开发者，能开发出让大家觉得好玩的游戏，也是这种理想，让我一直保持初心，不断进步。 刚入行时国内游戏环境很不好，大量劣质换皮手游充斥着市场，能让人眼前一亮的国产游戏少之又少。随着玩家对游戏的认知越来越广，对游戏的要求也随之越来越高，虽然很多公司死掉，但也有很多好的游戏团队因为玩家对游戏品质的追求提升而得以存活，不至于像之前完全被稀释掉。近年来国产手游也偶尔有大放异彩的时刻，而更好的消息是，国产独立游戏的关注度越来越高，好游戏的曝光率也随之增加，这不仅仅只是对于独立游戏圈的好消息，也说明整个国内游戏行业从换皮买量就能赚钱逐渐地往注重游戏品质转移，只不过目前这类高皮质的游戏多见于独立游戏。单机游戏就不多说了，在所谓的 氪金手游 上，收入居高的也大多是玩法或者艺术体验至少有一样方面做的很好的。 我也很庆幸自己在工作中能结识这些很棒的同事，也很庆幸现在做的项目也是自己本身就感兴趣想做的游戏，更庆幸的是自己身在一个热爱游戏想做出好游戏的团队。 人生苦短，年轻时抓紧时间去追求自己的理想，才不至于老去时回首往事，尽是些遗憾。 希望热爱游戏开发的小伙伴们，都能不忘初心，做出好的游戏。]]></content>
      <categories>
        <category>独立游戏</category>
      </categories>
      <tags>
        <tag>GameJam GGJ 游戏开发 独立游戏 游戏设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[切线空间(Tangent Space) 的计算与应用]]></title>
    <url>%2F2017%2F11%2F28%2F%E5%88%87%E7%BA%BF%E7%A9%BA%E9%97%B4-Tangent-Space-%E7%9A%84%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！如果在第三方阅读发现公式等格式有问题，请到原文地址阅读。 原文地址 概要本篇文章主要讲解计算机图形学中切线空间是如何计算的，且会以法线贴图的例子来验证切线空间是否计算正确，以及展现切线空间的用途. 本文需要读者掌握一定的 3D 坐标空间变换和简单光照相关的知识，以及法线贴图的基本知识（但切线空间不仅仅只用于法线贴图）。 认识切线空间什么是切线空间切线空间 (Tangent Space) 与 世界空间 (World Space) 和 观察空间 (View Space) 一样，都是一个坐标空间，它是由顶点所构成的平面的 UV 坐标轴以及表面的法线所构成，一般用 T (Tangent), B (Bitangent), N (Normal) 三个字母表示，即切线，副切线，法线， $T$ 对应 UV 中的 $U$, $B$ 对应 UV 中的 $V$，下图是切线空间的示意图： 这里可能会有一个疑问，就是为什么 $T$ 对应 UV 中的 $U$, $B$ 对应 UV 中的 $V$ 。理论上，只要 $T$ 和 $B$ 垂直且都位于三角形的平面内，就可以达到使用切线空间的目的，因为这样我们总可以把所有需要的数据变换到同一个坐标空间下，但由于我们知道 UV 坐标的值，所以用 UV 坐标来对应 $T$ 和 $B$ 计算出数据了。 为什么要有切线空间要理解为什么要有切线空间，可以从法线贴图入手。众所周知，绝大部分的法线贴图，颜色都是偏蓝色的，这是因为法线贴图中存储的法线向量大部分都是朝向或者接近 z 轴的，即 $(0, 0, 1)$，换算到 RGB 中，就是偏向蓝色，即 $(0.5, 0,5, 1)$ (后面的 Shader 中有算法)，这种贴图就是切线空间 (Tangent Space)下的贴图。这显然存在一个问题，想象一个位于世界坐标原点且没有进行任何变换的立方体，表面法线方向就有 6 个，因为有 6 个不同朝向的面（确切的说，可能是 12 个面，因为一个矩形一般由两个三角形组成），而且每个面完全相同，所以这时候我应该只需要一个面的法线贴图就可以了。但其实这时再用这种偏蓝色的法线贴图就不行了，因为立方体的上表面在世界空间的法线方向为 $(0, 1, 0)$，而在法线贴图中采样出来的法线基本都是接近于 $(0, 0, 1)$ 的，使用错误的法线会得到错误的光照结果。所以这时候需要做一张包含立方体所有面的法线信息的法线贴图，也就是模型空间 (Object Space)下的法线贴图，而这种贴图看起来就不单单是偏蓝色了，而是包含了多种颜色。 这样看起来好像也没什么问题，但其实用切线空间下的法线贴图要比用模型空间下的法线贴图要有一些优势： 可以复用：比如上文提到的立方体，如果每个面都完全相同，则可以只制作一个面的法线贴图，然后就可以复用到所有面上，类似的复用需求还有很多，这可以减小内存占用和包体大小。 纹理可以压缩：因为切线空间下，一般来说法线方向不会是朝向表面内部，即法线贴图中的 z 值不会是负数，而我们使用的法线又是归一化的，所以完全可以根据 x 和 y 的值来推导出 z 的值，所以贴图中只需要存储 x 和 y 的值即可，可进行纹理压缩。 待补充 综上所述，一般的法线贴图都是使用切线空间的，而直接使用切线空间下的法线贴图又会出现之前提到的立方体的那个问题，所以我们在使用前需要先进行切线空间相关的变换，把所需要的数据变换到同一个坐标空间下再进行计算（可以全部变换到世界空间也可以全部变换到切线空间）。 切线空间的计算求切线和副切线要进行切线空间相关的计算，需要先求出构成切线空间三个轴的单位基向量，然后就可以构造出从切线空间变换到世界空间的矩阵，从而进行之后的计算。 切线空间的计算可以通过前面的示意图来理解，这里为了方便，再放一次： 设： \Delta U_1 = U_2 - U_1 \Delta U_2 = U_3 - U_1 \Delta V_1 = V_2 - V_1 \Delta V_2 = V_3 - V_1则由图和共面向量基本定理可知： E_1 = \Delta U_1 T + \Delta V_1 B E_2 = \Delta U_2 T + \Delta V_2 B \Rightarrow (E_1x, E_1y, E_1z) = \Delta U_1(T_x, T_y, T_z) \; + \; \Delta V1(B_x, B_y, B_Z) \Rightarrow (E_2x, E_2y, E_2z) = \Delta U_2(T_x, T_y, T_z) \; + \; \Delta V2(B_x, B_y, B_Z)观察这两个等式，我们发现这其实可以写成矩阵乘法的形式，如下所示： \begin{pmatrix} E_1x & E_1y & E_1z \\ E_2x & E_2y & E_2z \\ \end{pmatrix} = \begin{pmatrix} \Delta U_1 & \Delta V_1 \\ \Delta U_2 & \Delta V_2 \\ \end{pmatrix} \begin{pmatrix} T_x & T_y & T_z \\ B_x & B_y & B_z \\ \end{pmatrix}如果你求解一下等号右边的矩阵乘法，你就会发现，他就是我们在上面得到的等式。根据这个矩阵形式的等式，我们不难求解 $TB$ 矩阵，只需要两边同时左乘 $\Delta U \Delta V$ 的逆矩阵，再进行计算即可,步骤如下： \begin{pmatrix} \Delta U_1 & \Delta V_1 \\ \Delta U_2 & \Delta V_2 \\ \end{pmatrix} ^{-1} \begin{pmatrix} E_1x & E_1y & E_1z \\ E_2x & E_2y & E_2z \\ \end{pmatrix} = \begin{pmatrix} T_x & T_y & T_z \\ B_x & B_y & B_z \\ \end{pmatrix}逆矩阵的计算公式为 矩阵的行列式的值的倒数再乘以它的伴随矩阵 (Adjugate Matrix, 如果对这些概念不熟悉需要读者自行查阅），其实伴随矩阵的求解并不容易，不过 二阶矩阵的伴随矩阵 有一个简单的公式，即 主对角线的元素互换，副对角线的元素乘以 $-1$ ，所以最终结果如下所示： \begin{pmatrix} T_x & T_y & T_z \\ B_x & B_y & B_z \\ \end{pmatrix} = \frac{1}{\Delta U_1 \Delta V_2 - \Delta U_2 \Delta V_1} \begin{pmatrix} \Delta V_2 & -\Delta V_1 \\ -\Delta U_2 & \Delta U_1 \\ \end{pmatrix} \begin{pmatrix} E_1x & E_1y & E_1z \\ E_2x & E_2y & E_2z \\ \end{pmatrix}似乎我们还缺少 $E_1$ 和 $E_2$ 的信息，但其实这个信息是已知的，因为他们就是三角形的两个边，而三角形的顶点坐标是我们知道的，所以求出 $T$ 和 $B$ 所需的数据我们都已经有了，只需要代入公式就可以了。 设： ratio = \frac{1}{\Delta U_1 \Delta V_2 - \Delta U_2 \Delta V_1}则： T_x = ratio * (\Delta V_2 E_1x - \Delta V_1 E_2x) T_y = ratio * (\Delta V_2 E_1y - \Delta V_1 E_2y) T_z = ratio * (\Delta V_2 E_1z - \Delta V_1 E_2z)$B$ 也可以如此求解，但其实只需要用 $T$ 和 法线向量 叉乘 即可。 归一化因为 $E_1$ 和 $E_2$ 是用顶点坐标表示的，而 $U$ 和 $V$ 是纹理坐标，他们的坐标单位是不同的，所以我们求出的结果自然不太可能是已经归一化了的，而我们使用坐标空间转换矩阵的时候需要的是归一化的坐标，所以我们需要进行归一化。 法线贴图的例子本节将以一个法线贴图的例子，来展示切线空间是如何工作的，在这个例子中，我只计算了漫反射等颜色（因为除了法线贴图外我只找到一张漫反射的贴图，但足够演示用了，不过光照效果看起来未必会很好），下面两张图是我使用的漫反射贴图和法线贴图： 计算顶点数据为了方便展示，我准备了一个立方体的顶点数据，一共有36个顶点（6个面，每个面2个三角形），为了这篇文章的编写方便，我采用直接绘制顶点而非索引的方式，并且之后的一些计算会有些暴力。 36个顶点数据如下所示，每一行分别为顶点坐标（3个），法线向量（3个），以及纹理坐标（2个），每6行为一个面。 12345678910111213141516171819202122232425262728293031323334353637383940414243float vertices[] = &#123; -0.5f, -0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 0.0f, 0.0f, 0.5f, -0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 1.0f, 0.0f, 0.5f, 0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 1.0f, 1.0f, 0.5f, 0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 1.0f, 1.0f, -0.5f, 0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 0.0f, 1.0f, -0.5f, -0.5f, -0.5f, 0.0f, 0.0f, -1.0f, 0.0f, 0.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.5f, -0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 1.0f, 1.0f, 0.5f, 0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 1.0f, 1.0f, -0.5f, 0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 0.0f, 1.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, -0.5f, 0.5f, 0.5f, -1.0f, 0.0f, 0.0f, 1.0f, 0.0f, -0.5f, 0.5f, -0.5f, -1.0f, 0.0f, 0.0f, 1.0f, 1.0f, -0.5f, -0.5f, -0.5f, -1.0f, 0.0f, 0.0f, 0.0f, 1.0f, -0.5f, -0.5f, -0.5f, -1.0f, 0.0f, 0.0f, 0.0f, 1.0f, -0.5f, -0.5f, 0.5f, -1.0f, 0.0f, 0.0f, 0.0f, 0.0f, -0.5f, 0.5f, 0.5f, -1.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.5f, 0.5f, -0.5f, 1.0f, 0.0f, 0.0f, 1.0f, 1.0f, 0.5f, -0.5f, -0.5f, 1.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.5f, -0.5f, -0.5f, 1.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.5f, -0.5f, 0.5f, 1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, 0.0f, 1.0f, 0.0f, -0.5f, -0.5f, -0.5f, 0.0f, -1.0f, 0.0f, 0.0f, 1.0f, 0.5f, -0.5f, -0.5f, 0.0f, -1.0f, 0.0f, 1.0f, 1.0f, 0.5f, -0.5f, 0.5f, 0.0f, -1.0f, 0.0f, 1.0f, 0.0f, 0.5f, -0.5f, 0.5f, 0.0f, -1.0f, 0.0f, 1.0f, 0.0f, -0.5f, -0.5f, 0.5f, 0.0f, -1.0f, 0.0f, 0.0f, 0.0f, -0.5f, -0.5f, -0.5f, 0.0f, -1.0f, 0.0f, 0.0f, 1.0f, -0.5f, 0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 0.0f, 1.0f, 0.5f, 0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 1.0f, 1.0f, 0.5f, 0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, -0.5f, 0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f, -0.5f, 0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 0.0f, 1.0f&#125;; 我们还要给每一行再增加6个数据，即 $T$ 和 $B$ 各 3 个坐标。上面一共有 288 个浮点数，让我直接再写 216 个会累死我的，所以切线空间的数据我直接用代码算出来了，实际使用过程中也许在导入模型的时候就可以直接导入切线空间了，当然没有也没关系，因为我已经讲了如何计算切线空间，并且这里也给出了一个例子。下面的代码就是计算切线空间的代码，就如之前说的，很暴力，我并没有多写几个循环来减少几行代码，何必呢。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061float tbnFloats[216]; // 36 个顶点的切线和副切线向量一共有 216 个浮点数// 一个立方体一共有 12 个三角形面(每 2 个构成一个立方体面)for (int i = 0; i &lt; 12; ++i)&#123; Vector3 tbn; int firstIndex = i * 24; // 三角形第 1 个顶点坐标起始索引 int secondIndex = firstIndex + 8; // 三角形第 2 个顶点坐标起始索引 int thirdIndex = secondIndex + 8; // 三角形第 3 个顶点坐标起始索引 // 求得一个三角形的三个顶点坐标 Vector3 pos1(vertices[firstIndex], vertices[firstIndex + 1], vertices[firstIndex + 2]); Vector3 pos2(vertices[secondIndex], vertices[secondIndex + 1], vertices[secondIndex + 2]); Vector3 pos3(vertices[thirdIndex], vertices[thirdIndex + 1], vertices[thirdIndex + 2]); // 求得一个三角形的三个顶点对应的 UV 坐标 Vector2 uv1(vertices[firstIndex + 6], vertices[firstIndex + 7]); Vector2 uv2(vertices[secondIndex + 6], vertices[secondIndex + 7]); Vector2 uv3(vertices[thirdIndex + 6], vertices[thirdIndex + 7]); ／/ 求出三角形的两条边的向量以及 UV 坐标之间的差向量，用于代入公式 // 需要注意的是，当表示 UV 坐标时，x 对应 U，y 对应 V Vector3 edge1 = pos2 - pos1; Vector3 edge2 = pos3 - pos1; Vector2 deltaUV1 = uv2 - uv1; Vector2 deltaUV2 = uv3 - uv1; // 计算切线和副切线向量 // 其实这里就是套用上面求出来的公式 Vector3 tangent; Vector3 bitTangent; GLfloat f = 1.0f / (deltaUV1.x * deltaUV2.y - deltaUV2.x * deltaUV1.y); tangent.x = f * (deltaUV2.y * edge1.x - deltaUV1.y * edge2.x); tangent.y = f * (deltaUV2.y * edge1.y - deltaUV1.y * edge2.y); tangent.z = f * (deltaUV2.y * edge1.z - deltaUV1.y * edge2.z); tangent = glm::normalize(tangent); bitTangent.x = f * (-deltaUV2.x * edge1.x + deltaUV1.x * edge2.x); bitTangent.y = f * (-deltaUV2.x * edge1.y + deltaUV1.x * edge2.y); bitTangent.z = f * (-deltaUV2.x * edge1.z + deltaUV1.x * edge2.z); bitTangent = glm::normalize(bitTangent); // 将每个三角形顶点的切线和副切线数据放到数组里 int startTBNIndex = i * 18; tbnFloats[startTBNIndex + 0] = tangent.x; tbnFloats[startTBNIndex + 1] = tangent.y; tbnFloats[startTBNIndex + 2] = tangent.z; tbnFloats[startTBNIndex + 3] = bitTangent.x; tbnFloats[startTBNIndex + 4] = bitTangent.y; tbnFloats[startTBNIndex + 5] = bitTangent.z; tbnFloats[startTBNIndex + 6] = tangent.x; tbnFloats[startTBNIndex + 7] = tangent.y; tbnFloats[startTBNIndex + 8] = tangent.z; tbnFloats[startTBNIndex + 9] = bitTangent.x; tbnFloats[startTBNIndex + 10] = bitTangent.y; tbnFloats[startTBNIndex + 11] = bitTangent.z; tbnFloats[startTBNIndex + 12] = tangent.x; tbnFloats[startTBNIndex + 13] = tangent.y; tbnFloats[startTBNIndex + 14] = tangent.z; tbnFloats[startTBNIndex + 15] = bitTangent.x; tbnFloats[startTBNIndex + 16] = bitTangent.y; tbnFloats[startTBNIndex + 17] = bitTangent.z;&#125; 接着我们将两个数组合并成一个新的顶点数组： 1234567891011121314151617181920212223float finishVertices[504];// 一共 36 个顶点，按照特定顺序合并即可for (int i = 0; i &lt; 36; ++i)&#123; int finishStartIndex = i * 14; int verticesStartIndex = i * 8; int tbnStartIndex = i * 6; finishVertices[finishStartIndex + 0] = vertices[verticesStartIndex + 0]; finishVertices[finishStartIndex + 1] = vertices[verticesStartIndex + 1]; finishVertices[finishStartIndex + 2] = vertices[verticesStartIndex + 2]; finishVertices[finishStartIndex + 3] = vertices[verticesStartIndex + 3]; finishVertices[finishStartIndex + 4] = vertices[verticesStartIndex + 4]; finishVertices[finishStartIndex + 5] = vertices[verticesStartIndex + 5]; finishVertices[finishStartIndex + 6] = vertices[verticesStartIndex + 6]; finishVertices[finishStartIndex + 7] = vertices[verticesStartIndex + 7]; finishVertices[finishStartIndex + 8] = tbnFloats[tbnStartIndex + 0]; finishVertices[finishStartIndex + 9] = tbnFloats[tbnStartIndex + 1]; finishVertices[finishStartIndex + 10] = tbnFloats[tbnStartIndex + 2]; finishVertices[finishStartIndex + 11] = tbnFloats[tbnStartIndex + 3]; finishVertices[finishStartIndex + 12] = tbnFloats[tbnStartIndex + 4]; finishVertices[finishStartIndex + 13] = tbnFloats[tbnStartIndex + 5];&#125; 这样我们就有一个新的包含 504 个浮点数的数组了，把数组抽象成行列的形式，每个顶点一行，每一行从左到右的形式是这样的：顶点坐标（3个），法线向量（3个），以及纹理坐标（2个），切线向量（3个），副切线向量（3个）。 但其实我这里多了一步，就是当我们求出切线后，只需要让其和三角形表面法线 叉乘 即可，因为他们都是互相垂直的，不过我这里没这么写。 不使用切线空间这个例子使用 OpenGL 编写，我没有全部给出代码，比如如何将这些数据传给 Shader 等，这些对于本篇文章并不重要，也不是本篇文章所要讲的，我在这里会直接给出相关的 Shader 片段，我觉得这就足够了。例子里只有一个立方体，一个平行光，且平行光垂直于立方体朝向世界坐标 Z 轴的一面，而法线贴图采用切线空间下的法线贴图，也就是看起来偏蓝色的法线贴图，这意味着大部分法线值都是偏向正 Z 轴的。 首先我们不使用法线贴图，只使用顶点数组里的顶点法线，来观察一下它的样子，如下图所示： 然后我们加入法线贴图，但不使用切线空间，直接从法线贴图中采样法线向量，再来看下它的样子，如下图所示： 通关观察可以发现，上面两张图中前者是相对正常的，因为整个世界里只有一个垂直于亮面的平行光，所以只能看到一个面有颜色，其它面都是黑色。而后者中，除了垂直于平行光的面，其余面也是有颜色的，这显然是不对的，因为按照物理法则，其余几个面不应该被任何光照到（我也没有添加环境光），所以应该是黑色的。之所以有这样错误的效果，是因为这个立方体六个面都用的相同的漫反射贴图和法线贴图，每一个面不管朝向哪里，采样出来的都是偏向正 Z 轴的值，所以 Shader 代码自然会认为这个面中大部分片段就是面向正 Z 轴的，而我们的平行光正好是照着负 Z 轴，所以这时每个面看起来都有了颜色，这也是我在前面提到的法线贴图的一个问题。 另外，如果你仔细发现，你会看到后者大面积对着屏幕的那一面要比前者大面积对着屏幕的那一面要稍微更有立体感，因为后者我使用了法线贴图，这是法线贴图最基本的作用。但这里的确不明显，因为我为了方便演示，并没有花时间调整出好的光照效果，毕竟这篇文章不是演示法线贴图的，而是用另一个方式去验证切线空间是否计算正确。 使用切线空间为了解决前面的问题，我们需要使用切线空间。切线空间有两种方式可以得到正确的光照结果： 将数据变换到 世界空间 来计算 将数据变换到 切线空间 来计算 很多人喜欢在世界空间中计算，因为将所有数据转换到世界空间再进行计算，是非常直观的，对于我们在讨论的问题也是如此。但这里我们使用第二种方式来计算，原因是它更高效。 如果我们使用第一种方式，我们需要将每个从法线贴图中采样出来的法线变换到世界空间，这一步是在 片段着色器 中完成的，因为必须知道每个片段对应的的法线值，而不能简单的在顶点着色器中采样出来然后再插值到片段着色器中。如果我们使用第二种方式，我们会在 顶点着色器 中把所需要的数据，在这个例子中有平行光方向向量，顶点坐标，观察坐标（因为这个例子只有一个漫反射贴图，所以其实这个数据并没什么卵用）变换到切线空间，然后在片段着色器中只需要采样出法线向量，不需要再进行其他转换就可以直接进行计算了。而一般来说片段着色器执行的次数远大于顶点着色器执行的次数，所以第二种方式一般来说更高效。 当然这里你可能有一个疑问，我们将一些数据从世界空间转换到切线空间，会涉及到矩阵的求逆，这一步是开销比较大的。理论上说，是的，但实际上，我们利用一个性质，即 正交矩阵的逆矩阵等于它的转置矩阵 就可以做到高效求逆矩阵，你在后面会看到。 顶点 Shader首先我们将顶点数组传入顶点着色器，然后构造 TBN 矩阵 来把一些数据变换到切线空间，最后再传入到片段着色器里。我先列出顶点着色器中所需要的数据(除传入的顶点数据外，其余数据都是在世界空间下)： 123456789101112131415161718192021222324#version 330 corelayout (location = 0) in vec3 vertexPosition; // 顶点坐标layout (location = 1) in vec3 vertexNormal; // 顶点法线layout (location = 2) in vec2 textureCoordinate; // 顶点纹理采样坐标layout (location = 3) in vec3 tangent; // 顶点切线layout (location = 4) in vec3 bitTangent; // 顶点副切线// 这是 OpenGL 中的 uniform 缓存，就是把一次渲染中不变的通用数据从外部代码传给 Shaderlayout (std140) uniform CameraInfo&#123; vec3 viewPosition; // 摄像机位置（观察位置）&#125;;// 平行光的数据struct DirectionalLight&#123; vec3 direction; // 方向 vec3 diffuseColor; // 漫反射颜色&#125;;uniform mat4 mvpMatrix;uniform mat4 modelMatrix;uniform DirectionalLight directionalLight; 然后我们还需要定义输出给片段着色器的数据： 12345678out V_OUT&#123; vec2 textureCoordinate; // 纹理坐标 vec3 vertexPosition; // 切线空间顶点坐标 vec3 normal; // 发现向量 vec3 viewPosition; // 切线空间观察坐标 vec3 directionalLightDirection; // 切线空间平行光方向&#125; v_out; 这些数据定义好后，我们就可以着手编写转换各个数据到切线空间的代码了： 1234567891011121314151617181920212223242526void main()&#123; // 计算顶点的世界坐标 vec4 vertexPositionVector = vec4(vertexPosition, 1.f); gl_Position = mvpMatrix * vertexPositionVector; // 计算法线矩阵(这个矩阵可以使法线的坐标空间变换更精确，详细信息可以查阅【法线矩阵】 或 【Normal Transform】) mat3 normalMatrix = transpose(inverse(mat3(modelMatrix))); // 求 TBN 矩阵，三个向量均变换到世界空间 vec3 T = normalize(normalMatrix * tangent); vec3 B = normalize(normalMatrix * bitTangent); vec3 N = normalize(normalMatrix * vertexNormal); // 求 TBN 矩阵的逆矩阵，因为 TBN 矩阵由三个互相垂直的单位向量组成，所以它是一个正交矩阵 // 正如前面所说，正交矩阵的逆矩阵等于它的转置，所以无需真的求逆矩阵 // 详情可查阅 【正交矩阵】 或 【Orthogonal Matrix】 mat3 inverseTBN = transpose(mat3(T, B, N)); // 将一些数据从世界空间变换到切线空间（并非所有数据都需要变换），然后传给片段着色器 v_out.directionalLightDirection = inverseTBN * directionalLight.direction; v_out.vertexPosition = inverseTBN * vec3(gl_Position); v_out.viewPosition = inverseTBN * viewPosition; v_out.textureCoordinate = textureCoordinate; v_out.normal = N;&#125; 写到这里我发现，我本来想只放出 Shader 片段的，但最后还是把整个顶点着色器的代码都写上了。我在里面添加了详细的注释，应该不会有什么很困惑的地方。 片段 Shader由于我们将数据都变换到了切线空间下，那么片段着色器在计算的时候就方便多了，因为它们都在同一个空间下了。同样我们先定义所需要的数据： 1234567891011121314151617181920212223242526272829#version 330 coreout vec4 f_color; // 输出的颜色// 这个跟顶点着色器中的 out 一致in V_OUT&#123; vec2 textureCoordinate; vec3 vertexPosition; vec3 normal; vec3 viewPosition; vec3 directionalLightDirection;&#125; v_out;struct Material&#123; sampler2D diffuseTexture; // 漫反射贴图 sampler2D normalTexture; // 法线贴图&#125;;// 跟顶点着色器中的一致struct DirectionalLight&#123; vec3 direction; vec3 diffuseColor;&#125;;uniform Material material; // 材质uniform DirectionalLight directionalLight; // 平行光信息 最后计算最终的颜色： 12345678910111213141516171819202122vec3 viewDirection; // 观察方向vec3 CaculateDiractionalLightColor()&#123; // 从法线贴图中采样出数据，并转换成法线值 // 转过算法为：贴图中存储 0 到 1 的值，而法线值是 -1 到 1 vec3 normal = vec3(texture(material.normalTexture, v_out.textureCoordinate)); normal = normalize(normal * 2.0 - 1.0); // 计算漫反射 float diffuseRatio = max(dot(-v_out.directionalLightDirection, normal), 0.0); vec3 diffuseColor = directionalLight.diffuseColor * diffuseRatio * vec3(texture(material.diffuseTexture0, v_out.textureCoordinate)); // 因为这个例子只用了漫反射贴图和法线贴图，所以其余如镜面反射或者环境光等就不计算了 return diffuseColor;&#125;void main()&#123; viewDirection = normalize(v_out.vertexPosition - v_out.viewPosition); f_color = vec4(CaculateDiractionalLightColor(), 1.0); // 输出最终颜色&#125; 例子的结果最终的结果如下图所示： 从图中可以看到，除了正对着平行光的一面外，其余面在凹凸的地方会有一点颜色，而其他地方依然是黑色。这是因为对于这个砖墙的图来说，在法线贴图中砖的凹凸处所对应的法线向量显然不是 $(0, 0, 1)$ ，所以在这个使用了切线空间的例子中，平行于平行光方向的面转换到切线空间后，可以直接对法线贴图进行采样，而砖墙的大部分面积采样出来的法线向量是 $(0, 0, 1)$ ，所以对于平行于平行光方向的墙面来说，大部分像素的法线向量都垂直于平行光照射的方向，所以计算出的颜色自然为0，而砖墙的凹凸处的法线值不垂直于平行光照射的方向，所以会得到一些颜色，这应该足以说明我们的切线空间计算结果是正确的。]]></content>
      <categories>
        <category>图形</category>
      </categories>
      <tags>
        <tag>图形 数学 切线空间 法线贴图 视差贴图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[判断单向链表是否有环及求环入口的算法数学证明]]></title>
    <url>%2F2017%2F10%2F09%2F%E5%88%A4%E6%96%AD%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8%E6%98%AF%E5%90%A6%E6%9C%89%E7%8E%AF%E5%8F%8A%E6%B1%82%E7%8E%AF%E5%85%A5%E5%8F%A3%E7%9A%84%E7%AE%97%E6%B3%95%E6%95%B0%E5%AD%A6%E8%AF%81%E6%98%8E%2F</url>
    <content type="text"><![CDATA[读者您好：本篇文章未经作者本人授权，禁止任何形式的转载，谢谢！ 概要本篇文章，主要讲解 title 中所描述算法的原理及数学证明。需要注意的是，本篇中出现的代码未必是完整代码，可能只是一个关键代码块，且采用 C++ 编写。 判断链表是否有环当单向链表中存在环的时候，遍历此链表会发生无限循环，无法到达末尾（实际上并没有末尾）的情况，所以在可能发生这种情况的时候，需要检查链表中是否存在一个环。 算法算法很简单，设置两个指针，分别为快指针（fast）和慢指针（slow），快指针每次向前走两步，慢指针每次走一步。如果快指针指向了 NULL，那么说明此链表中没有坏，因为有环会发生无限循环，不可能走到末尾。而在有环的情况下，两个指针会在环里绕圈，最终指向同一个地址，即两个指针相遇，根据这个就可以终止遍历代码且证实链表有环。 附上关键代码： 12345678910ListNode *slow = head-&gt;next;ListNode *fast = slow-&gt;next;while (fast &amp;&amp; slow != fast)&#123; slow = slow-&gt;next; fast = fast-&gt;next ? fast-&gt;next-&gt;next : NULL;&#125;return fast ? true : false; 有环时两个指针一定会相遇的数学证明在做这道题的时候可能会有疑惑：为什么在有环的时候两个指针一定会相遇？这里给出数学证明。 当 slow 指针一步步走到环的入口时（注意此时 fast 已经在环里了，因为它比 slow 要快），设： 链表头指针 head 到链表环的入口处的距离为 $ L_1 $ fast 指针距离环的入口的距离为 $ L_2 $ fast 已经在环内走了 $ N_1 $ 圈（向下取整） 假设 slow 再经过 $ i $ 步与 fast 相遇 环的周长为 $ C $ fast 和 slow 走过的总路程分别为 $ disFast $ 和 $ disSlow $ 示意图如下： 则当 slow 走到环入口时，可得知： disFast = L_1 + L_2 + N_1C disSlow = L_1又因为 fast 每次走两步，即比 slow 快一倍，所以 若两个指针相遇，则有： (disSlow + i - L_1) \; mod \; C = (disFast + 2i - L_1) \; mod \; C减去 $ L_1 $ 是为了减掉不在环内的长度从而求得相遇点相对于环入口的距离，由于等式两边的值实际上是相对于环入口的距离，所以有： i \; mod \; C = (L_2 + N_1C + 2i) \; mod \; C \Rightarrow (L_2 + N_1C + i) \; mod \; C = 0 \Rightarrow (L_2 + i) \; mod \; C = 0 \; (加减 C 的整数倍对于取模来说没有影响）可以看到， $L_2$ 和 $i$ 总和等于环的周长的整数倍，这个等式是成立的，实际上我们也求出了 $i$ 的值。结合图和最终的等式，我们可以看到，对于任意 $L_2$ ，都可以求出无数个 $i$ 值，每个值都对应一个周长的整数倍，而对于每一个 $i$ 值，最终相遇的位置都一样，这也很好理解，当 $slow$ 和 $fast$ 相遇后，由于 2 倍速度的关系，当 $slow$ 继续走半圈的时候，$fast$ 走了一圈回到了之前的相遇点，当 $slow$ 再走半圈回到之前的相遇点， $fast$ 又走了一圈再次回到之前的相遇点。 这就是对于在有环的单链表中快慢指针一定会相遇的数学证明。 求环的入口在上一个问题之后，还有一个相关的问题，即如果此链表有环，求环的入口节点。直接想此算法可能比较难解，所以这个问题可以尝试着从数学上入手。 数学设 (注意与上一个问题所表示的含义可能有不同) ： $ L_1 $ 为链表头 head 到环入口的距离 $ L_2 $ 为从环入口向前到相遇点的距离 $ L_3 $ 为从相遇点向前到环入口的距离 (按照指针前进的方向计算) $ C $ 为环的周长 $ N_1 $ 和 $ N_2 $ 分别为 slow 和 fast 在相遇时走过的圈数（向下取整） $ disSlow $ 和 $ disFast $ 分别为 slow 和 fast 在相遇时走过的距离 示意图如下： 则： disSlow = L_1 + L_2 + N_1C disFast = L_1 + L_2 + N_2C又因为 fast 速度是 slow 的 $ 2 $ 倍，所以： disSlow * 2 = disFast \Rightarrow 2(L_1 + L_2 + N_1C) = L_1 + L_2 + N_2C \Rightarrow L_1 + L_2 + 2N_1C = N_2C \Rightarrow L_1 = (N_2 - 2N_1)C - L_2因为 $fast$ 的速度是 $slow$ 的两倍，所以 $N_2$ 至少是 $N_1$ 的两倍（至少而不是恰好是因为 $fast$ 进入环时 $slow$ 可能还没进入环，所以 $fast$ 可能会先在环内走几圈）， 即 N_2 >= 2N_1这里其实还可以求出的是，当 $N_2$ 等于 2 倍的 $N_1$ 的时候，$L_1$ 和 $L_2$ 都为 0 ，也就是整个链表就是一个环 。 由此可以看出，$ L_1 $ 即链表头 head 到环入口的距离就等于 $(N_2 - 2N_1)C - L_2$，其实就等于 $L_3 + (N_2 - 2N_1 - 1)C$ （注意 $L_3$ 是按照指针前进方向算的，并不是最小距离，所以这个结果对于整个链表都是环也是有效的） ，而从相遇点向前走 $L_3 + (N_2 - 2N_1 - 1)C$ 的距离，正好就走到了环的入口（如果没理解可以在图上比划一下即可），所以我们就可以推导出算法，即：让两个指针其中一个从链表头 head 出发，一次走一步，让另一个指针从相遇点出发，也一次走一步，相遇点就是环的入口。 算法关键代码如下： 1234567slow = head;while (slow != fast)&#123; slow = slow-&gt;next; fast = fast-&gt;next;&#125; 注意事项这里有一个小坑，在算法的最最开始，可以让 slow 和 fast 都为 head 指针，或者 slow 为 head 的下一个节点，fast 为下两个节点。如果让 slow 为 head 指针，fast 为下一个节点，则可能无法求出环的入口，甚至可能陷入死循环。但对于第一个问题，这个步骤没有影响。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法 链表 数学</tag>
      </tags>
  </entry>
</search>
